{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210812 ML_프로젝트 흐름총정리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFdtIjE9NZmP2X9Rx7WZvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammobam/Display_SensorData/blob/main/210812_ML_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_%ED%9D%90%EB%A6%84%EC%B4%9D%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OoaDdWpr9aV",
        "outputId": "87bc6c4b-a0a2-4ba1-9efa-6b59a2162dda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCOtFFGOsFBV"
      },
      "source": [
        "# 머신러닝을 이용한 중요 피처 찾기\n",
        "- 데이터 : 디스플레이 공정별 센서 측정값. (.csv)\n",
        "\n",
        "## 할 것\n",
        "- csv 파일을 넣으면 머신러닝까지 자동으로 수행되도록 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF5ijLuKVRU4"
      },
      "source": [
        "## 패키지 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIMRmTYTtbYv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "#help(pd.read_csv)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO-eaPBKswdE"
      },
      "source": [
        "## 데이터 불러오기\n",
        "- 데이터 불러오기\n",
        "- 원본데이터 보존을 위해 copy 데이터 만들어서 사용하기\n",
        "- (선택) 생산라인 L, R 구분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk8Qj6icr09h"
      },
      "source": [
        "# 데이터 불러오기\n",
        "# 첫번째 열을 인덱스로 사용함\n",
        "fact_data = pd.read_csv('/content/drive/MyDrive/나무플래닛/1. 데이터_디스플레이/factory_glass_2016.zip', encoding='cp949', index_col=0)\n",
        "    # encoding : 파일이 안 열리면 인코딩 옵션을 확인하자. utf-8, cp949등으로 설정해봄.\n",
        "    # index_col : 인덱스로 사용할 columns의 인덱스를 설정"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "tg4JBGvt7205",
        "outputId": "8881d2fa-594b-4da0-8f88-3d566d6a9c89"
      },
      "source": [
        "# 데이터 확인\n",
        "fact_data.info()\n",
        "fact_data.head()\n",
        "    # 840 컬럼 x 8145개 행이 있음\n",
        "    # 데이터 타입은 float과 int형으로 모두 숫자 데이터. 연산 가능함."
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8145 entries, 2016-01-01 07 to 2016-12-31 23\n",
            "Columns: 840 entries, LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101 to R.Vac\n",
            "dtypes: float64(834), int64(6)\n",
            "memory usage: 52.3+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101</th>\n",
              "      <th>LIFT.OUT.ROL.MTR.M2.SPD.1WSI40102</th>\n",
              "      <th>LIFT.OUT.ROL.MTR.M3.SPD.1WSI40103</th>\n",
              "      <th>LEHR.DRV.MTR..M4.1.SPD.1WSI40104</th>\n",
              "      <th>LEHR.DRV.MTR..M4.2.SPD.1WSI40105</th>\n",
              "      <th>LEHR.DRV.MTR..M5.1.SPD.1WSI40106</th>\n",
              "      <th>LEHR.DRV.MTR..M5.2.SPD.1WSI40107</th>\n",
              "      <th>LEHR.DRV.MTR..M6.1.SPD.1WSI40108</th>\n",
              "      <th>LEHR.DRV.MTR..M6.2.SPD.1WSI40109</th>\n",
              "      <th>LEHR.DRV.MTR..M7.1.SPD.1WSI40110</th>\n",
              "      <th>LEHR.DRV.MTR..M7.2.SPD.1WSI40111</th>\n",
              "      <th>LEHR.DRV.MTR..M8.1.SPD.1WSI40112</th>\n",
              "      <th>LEHR.DRV.MTR..M8.2.SPD.1WSI40113</th>\n",
              "      <th>LEHR.DRV.MTR..M9.1.SPD.1WSI40114</th>\n",
              "      <th>LEHR.DRV.MTR..M9.2.SPD.1WSI40115</th>\n",
              "      <th>DRIVE.MOTOR.M10.1.SPEED.1WSI40116</th>\n",
              "      <th>LEHR.DRV.MTR..M10.2.SPD.1WSI40117</th>\n",
              "      <th>LEHR.DRV.MTR..M11.1.SPD.1WSI40118</th>\n",
              "      <th>DRIVE.MOTOR.M11.2.SPEED.1WSI40119</th>\n",
              "      <th>LEHR.DRV.MTR..M12.1.SPD.1WSI40120</th>\n",
              "      <th>LEHR.DRV.MTR..M12.2.SPD.1WSI40121</th>\n",
              "      <th>LEHR.DRV.MTR..M13.1.SPD.1WSI40122</th>\n",
              "      <th>LEHR.DRV.MTR..M13.2.SPD.1WSI40123</th>\n",
              "      <th>LEHR.DRV.MTR..M14.1.SPD.1WSI40124</th>\n",
              "      <th>LEHR.DRV.MTR..M14.2.SPD.1WSI40125</th>\n",
              "      <th>LEHR.DRV.MTR..M15.1.SPD.1WSI40126</th>\n",
              "      <th>LEHR.DRV.MTR..M15.2.SPD.1WSI40127</th>\n",
              "      <th>LEHR.DRV.MTR..M16.1.SPD.1WSI40128</th>\n",
              "      <th>DRIVE.MOTOR.M16.2.SPEED.1WSI40129</th>\n",
              "      <th>LEHR.DRV.MTR..M17.1.SPD.1WSI40130</th>\n",
              "      <th>LEHR.DRV.MTR..M17.2.SPD.1WSI40131</th>\n",
              "      <th>LEHR.DRV.MTR..M18.1.SPD.1WSI40132</th>\n",
              "      <th>LEHR.DRV.MTR..M18.2.SPD.1WSI40133</th>\n",
              "      <th>DRIVE.MOTOR.M19.1.SPEED.1WSI40134</th>\n",
              "      <th>LEHR.DRV.MTR..M19.2.SPD.1WSI40135</th>\n",
              "      <th>X1WOS45101_PV</th>\n",
              "      <th>X1WOS45102_PV</th>\n",
              "      <th>X1WOS45103_PV</th>\n",
              "      <th>X1WOS45104_PV</th>\n",
              "      <th>X1WOS45105_PV</th>\n",
              "      <th>...</th>\n",
              "      <th>S_C1_C2_L_L</th>\n",
              "      <th>S_C1_C2_L_R</th>\n",
              "      <th>S_C2_C3_U_L</th>\n",
              "      <th>S_C2_C3_U_R</th>\n",
              "      <th>S_C2_C3_L_L</th>\n",
              "      <th>S_C2_C3_L_R</th>\n",
              "      <th>S_C3_C4_U_L</th>\n",
              "      <th>S_C3_C4_U_R</th>\n",
              "      <th>S_C3_C4_L_L</th>\n",
              "      <th>S_C3_C4_L_R</th>\n",
              "      <th>S_AB1_AB11_L</th>\n",
              "      <th>S_AB1_AB11_R</th>\n",
              "      <th>S_AB11_AB7_L</th>\n",
              "      <th>S_AB11_AB7_R</th>\n",
              "      <th>S_AB7_C4_L</th>\n",
              "      <th>S_AB7_C4_R</th>\n",
              "      <th>S_C4_RET_L</th>\n",
              "      <th>S_C4_RET_R</th>\n",
              "      <th>S_RET_F_L</th>\n",
              "      <th>S_RET_F_R</th>\n",
              "      <th>STD_U_L</th>\n",
              "      <th>STD_U_R</th>\n",
              "      <th>STD_L_L</th>\n",
              "      <th>STD_L_R</th>\n",
              "      <th>STD_GLS_L</th>\n",
              "      <th>STD_GLS_R</th>\n",
              "      <th>투입.LEFT.</th>\n",
              "      <th>투입.RIGHT.</th>\n",
              "      <th>ROLLDOWN.폐기.LEFT.</th>\n",
              "      <th>진공패드.폐기.LEFT.</th>\n",
              "      <th>ROLLDOWN.폐기.RIGHT.</th>\n",
              "      <th>진공패드.폐기.RIGHT.</th>\n",
              "      <th>폐기율...</th>\n",
              "      <th>ROLLDOWN.진공패드.폐기율..LEFT.</th>\n",
              "      <th>ROLLDOWN.진공패드.폐기율..RIGHT.</th>\n",
              "      <th>ROLLDOWN.진공패드.폐기율..전체.</th>\n",
              "      <th>L.RD</th>\n",
              "      <th>L.Vac</th>\n",
              "      <th>R.RD</th>\n",
              "      <th>R.Vac</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dat...date.name.</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-01 07</th>\n",
              "      <td>-1.772682</td>\n",
              "      <td>-1.713219</td>\n",
              "      <td>-1.734851</td>\n",
              "      <td>-1.590051</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.575213</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.824581</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.8189</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.806012</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.776634</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.766604</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.638207</td>\n",
              "      <td>-1.728206</td>\n",
              "      <td>-1.674911</td>\n",
              "      <td>-1.641818</td>\n",
              "      <td>-1.662151</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.622314</td>\n",
              "      <td>-1.653428</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.807954</td>\n",
              "      <td>-1.73</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>-1.620631</td>\n",
              "      <td>-1.517655</td>\n",
              "      <td>-1.804912</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.195736</td>\n",
              "      <td>0.706941</td>\n",
              "      <td>1.477203</td>\n",
              "      <td>0.410847</td>\n",
              "      <td>0.491620</td>\n",
              "      <td>0.942180</td>\n",
              "      <td>2.776941</td>\n",
              "      <td>2.492437</td>\n",
              "      <td>2.060406</td>\n",
              "      <td>2.612283</td>\n",
              "      <td>1.726404</td>\n",
              "      <td>1.461145</td>\n",
              "      <td>-1.192642</td>\n",
              "      <td>-1.134471</td>\n",
              "      <td>2.599429</td>\n",
              "      <td>2.690433</td>\n",
              "      <td>-0.365598</td>\n",
              "      <td>-0.659319</td>\n",
              "      <td>-1.963403</td>\n",
              "      <td>-1.621407</td>\n",
              "      <td>0.523950</td>\n",
              "      <td>1.951349</td>\n",
              "      <td>2.248106</td>\n",
              "      <td>2.767676</td>\n",
              "      <td>3.012706</td>\n",
              "      <td>3.069007</td>\n",
              "      <td>80</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>11.69</td>\n",
              "      <td>8.75</td>\n",
              "      <td>14.86</td>\n",
              "      <td>11.69</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 08</th>\n",
              "      <td>-1.772682</td>\n",
              "      <td>-1.713219</td>\n",
              "      <td>-1.734851</td>\n",
              "      <td>-1.590051</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.575213</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.824581</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.8189</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.806012</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.776634</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.766604</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.638207</td>\n",
              "      <td>-1.728206</td>\n",
              "      <td>-1.674911</td>\n",
              "      <td>-1.641818</td>\n",
              "      <td>-1.662151</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.622314</td>\n",
              "      <td>-1.653428</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.807954</td>\n",
              "      <td>-1.73</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>-1.620631</td>\n",
              "      <td>-1.517655</td>\n",
              "      <td>-1.804912</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.500742</td>\n",
              "      <td>0.822657</td>\n",
              "      <td>1.495204</td>\n",
              "      <td>0.397591</td>\n",
              "      <td>0.587871</td>\n",
              "      <td>0.938186</td>\n",
              "      <td>2.888919</td>\n",
              "      <td>2.573187</td>\n",
              "      <td>2.161149</td>\n",
              "      <td>2.664726</td>\n",
              "      <td>1.682081</td>\n",
              "      <td>1.414518</td>\n",
              "      <td>-1.109125</td>\n",
              "      <td>-1.042269</td>\n",
              "      <td>2.588703</td>\n",
              "      <td>2.654307</td>\n",
              "      <td>-0.348979</td>\n",
              "      <td>-0.560103</td>\n",
              "      <td>-1.978936</td>\n",
              "      <td>-1.810022</td>\n",
              "      <td>0.566521</td>\n",
              "      <td>2.010125</td>\n",
              "      <td>2.364418</td>\n",
              "      <td>2.842630</td>\n",
              "      <td>3.022998</td>\n",
              "      <td>3.069274</td>\n",
              "      <td>92</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>7.19</td>\n",
              "      <td>2.17</td>\n",
              "      <td>13.33</td>\n",
              "      <td>7.19</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 09</th>\n",
              "      <td>-1.772682</td>\n",
              "      <td>-1.713219</td>\n",
              "      <td>-1.734851</td>\n",
              "      <td>-1.590051</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.575213</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.824581</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.8189</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.806012</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.776634</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.766604</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.638207</td>\n",
              "      <td>-1.728206</td>\n",
              "      <td>-1.674911</td>\n",
              "      <td>-1.641818</td>\n",
              "      <td>-1.662151</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.622314</td>\n",
              "      <td>-1.653428</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.807954</td>\n",
              "      <td>-1.73</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>-1.620631</td>\n",
              "      <td>-1.517655</td>\n",
              "      <td>-1.804912</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.164556</td>\n",
              "      <td>0.962210</td>\n",
              "      <td>1.552127</td>\n",
              "      <td>0.460702</td>\n",
              "      <td>0.397216</td>\n",
              "      <td>0.843443</td>\n",
              "      <td>2.868644</td>\n",
              "      <td>2.486441</td>\n",
              "      <td>2.183298</td>\n",
              "      <td>2.638130</td>\n",
              "      <td>1.632955</td>\n",
              "      <td>1.359022</td>\n",
              "      <td>-0.986580</td>\n",
              "      <td>-0.928583</td>\n",
              "      <td>2.550175</td>\n",
              "      <td>2.606185</td>\n",
              "      <td>-0.456071</td>\n",
              "      <td>-0.644073</td>\n",
              "      <td>-1.878611</td>\n",
              "      <td>-1.742395</td>\n",
              "      <td>0.545936</td>\n",
              "      <td>2.002820</td>\n",
              "      <td>2.397034</td>\n",
              "      <td>2.817728</td>\n",
              "      <td>2.936967</td>\n",
              "      <td>2.969952</td>\n",
              "      <td>64</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>7.81</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 10</th>\n",
              "      <td>-1.772682</td>\n",
              "      <td>-1.713219</td>\n",
              "      <td>-1.734851</td>\n",
              "      <td>-1.590051</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.575213</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.824581</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.8189</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.806012</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.776634</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.766604</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.638207</td>\n",
              "      <td>-1.728206</td>\n",
              "      <td>-1.674911</td>\n",
              "      <td>-1.641818</td>\n",
              "      <td>-1.662151</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.622314</td>\n",
              "      <td>-1.653428</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.807954</td>\n",
              "      <td>-1.73</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>-1.620631</td>\n",
              "      <td>-1.517655</td>\n",
              "      <td>-1.804912</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.824056</td>\n",
              "      <td>0.686628</td>\n",
              "      <td>1.586571</td>\n",
              "      <td>0.411229</td>\n",
              "      <td>0.878934</td>\n",
              "      <td>1.019915</td>\n",
              "      <td>2.834358</td>\n",
              "      <td>2.354249</td>\n",
              "      <td>2.199586</td>\n",
              "      <td>2.623425</td>\n",
              "      <td>1.563766</td>\n",
              "      <td>1.253063</td>\n",
              "      <td>-0.885353</td>\n",
              "      <td>-0.860442</td>\n",
              "      <td>2.518261</td>\n",
              "      <td>2.551495</td>\n",
              "      <td>-0.463717</td>\n",
              "      <td>-0.585540</td>\n",
              "      <td>-1.863727</td>\n",
              "      <td>-1.845004</td>\n",
              "      <td>0.549254</td>\n",
              "      <td>2.047995</td>\n",
              "      <td>2.399854</td>\n",
              "      <td>2.810619</td>\n",
              "      <td>2.876398</td>\n",
              "      <td>2.914596</td>\n",
              "      <td>68</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.96</td>\n",
              "      <td>10.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.96</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.103</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 11</th>\n",
              "      <td>-1.772682</td>\n",
              "      <td>-1.713219</td>\n",
              "      <td>-1.734851</td>\n",
              "      <td>-1.590051</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.575213</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.824581</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.8189</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.779407</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.806012</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.776634</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.766604</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.775051</td>\n",
              "      <td>-1.638207</td>\n",
              "      <td>-1.728206</td>\n",
              "      <td>-1.674911</td>\n",
              "      <td>-1.641818</td>\n",
              "      <td>-1.662151</td>\n",
              "      <td>-1.636293</td>\n",
              "      <td>-1.622314</td>\n",
              "      <td>-1.653428</td>\n",
              "      <td>-1.548119</td>\n",
              "      <td>-1.807954</td>\n",
              "      <td>-1.73</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>-1.620631</td>\n",
              "      <td>-1.517655</td>\n",
              "      <td>-1.804912</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.504655</td>\n",
              "      <td>0.954654</td>\n",
              "      <td>1.540081</td>\n",
              "      <td>0.393697</td>\n",
              "      <td>0.795806</td>\n",
              "      <td>0.917465</td>\n",
              "      <td>2.852398</td>\n",
              "      <td>2.365165</td>\n",
              "      <td>2.159633</td>\n",
              "      <td>2.582810</td>\n",
              "      <td>1.476850</td>\n",
              "      <td>1.144747</td>\n",
              "      <td>-0.852229</td>\n",
              "      <td>-0.821249</td>\n",
              "      <td>2.521009</td>\n",
              "      <td>2.541783</td>\n",
              "      <td>-0.421995</td>\n",
              "      <td>-0.580300</td>\n",
              "      <td>-1.903504</td>\n",
              "      <td>-1.781370</td>\n",
              "      <td>0.610913</td>\n",
              "      <td>2.101178</td>\n",
              "      <td>2.379341</td>\n",
              "      <td>2.797094</td>\n",
              "      <td>2.858177</td>\n",
              "      <td>2.873929</td>\n",
              "      <td>36</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 840 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101  ...  R.Vac\n",
              "dat...date.name.                                     ...       \n",
              "2016-01-01 07                             -1.772682  ...  0.041\n",
              "2016-01-01 08                             -1.772682  ...  0.000\n",
              "2016-01-01 09                             -1.772682  ...  0.000\n",
              "2016-01-01 10                             -1.772682  ...  0.000\n",
              "2016-01-01 11                             -1.772682  ...  0.000\n",
              "\n",
              "[5 rows x 840 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTnGYnCNLCde"
      },
      "source": [
        "### ** 데이터 복사에 관하여\n",
        "- 복사를 하는 이유\n",
        "    - 데이터를 복사하여 작업하면 원본 데이터의 유실을 예방할 수 있음.\n",
        "    - 같은 데이터를 새로운 객체에 두 번 할당하는 경우에 비해 memory를 아낄 수 있음\n",
        "- 복사의 종류\n",
        "    -  a = 10, b = a로 복사하면 참조만 복사. 같은 데이터\n",
        "    - [mutable문제 발생] 어느 한 쪽을 수정하면 다른 쪽도 변경됨\n",
        "    - 얕은 복사(.copy())\n",
        "        - 겉 객체를 복사하여 다른 객체 할당함\n",
        "        - 원소가 다시 리스트 등의 객체인 경우, 그 원소객체의 참조만 복사되어 mutable 문제가 발생함\n",
        "    - 깊은 복사(.deepcopy())\n",
        "        - 겉 객체, 원소 객체가 2중인 경우 그 객체까지 복사 (예시 : 리스트 안에 다시 리스트)\n",
        "        - mutable한 문제가 해결됨\n",
        "- 더 알아보기 : 2중 배열 만들어서 copy, deepcopy 비교하기\n",
        "    - 참고링크 : https://maeng-test-blog.tistory.com/98"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtO4vzCYNbqd"
      },
      "source": [
        "# 원본데이터의 보존을 위해 얕은 복사를 수행함\n",
        "# fact_data 데이터는 숫자형으로 얕은 복사만 수행해도 됨\n",
        "fact_data_copy = fact_data.copy()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfgdkOz9syW9"
      },
      "source": [
        "## 데이터 전처리\n",
        "- 결측치 처리\n",
        "- 분산 0인 피처 제거\n",
        "- 상관관계 높은 피처 제거\n",
        "- VIF > 30 이상의 피처 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p26tE_THsNRO"
      },
      "source": [
        "### 컬럼 제외하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myvoo8akXH_f"
      },
      "source": [
        "#### 레이블 컬럼 제외하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FizlEG_WZhA",
        "outputId": "2e1bb06b-a133-447b-e70b-fae5bc5b0dda"
      },
      "source": [
        "# 레이블 컬럼 제외하기\n",
        "col_label = ['L.RD', 'L.Vac', 'R.RD', 'R.Vac']\n",
        "col_use = []\n",
        "for col in fact_data.columns:\n",
        "    if col not in col_label:\n",
        "       col_use.append(col)\n",
        "print(len(col_use)) # 146개\n",
        "\n",
        "# 데이터프레임 만들기\n",
        "fact_data = fact_data[col_use]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8hn6ZcDXd6P",
        "outputId": "71388ebe-d7bd-403b-82f3-9f230b8acaec"
      },
      "source": [
        "# 레이블 컬럼에 혹시 결측치 있었나 확인\n",
        "fact_data_copy[col_label].isnull().sum()\n",
        "# 없음"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "L.RD     0\n",
              "L.Vac    0\n",
              "R.RD     0\n",
              "R.Vac    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0EYwCEEWWI_"
      },
      "source": [
        "#### 아무리봐도 피처는 아닌 것 같은 컬럼 제거하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnjeUV_OW9mH",
        "outputId": "ec48e12e-1111-478d-a119-c260bfd21228"
      },
      "source": [
        "# 아무리봐도 피처는 아닌 것 같은 컬럼 제거하기\n",
        "col_susang = ['투입.LEFT.', 'ROLLDOWN.폐기.LEFT.', '진공패드.폐기.LEFT.','ROLLDOWN.진공패드.폐기율..LEFT.', '폐기율...']\n",
        "col_use = []\n",
        "for col in fact_data.columns:\n",
        "    if col not in col_susang:\n",
        "       col_use.append(col)\n",
        "print(len(col_use)) # 146개\n",
        "\n",
        "# 데이터프레임 만들기\n",
        "fact_data = fact_data[col_use]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwpuU3uKrXQ7"
      },
      "source": [
        "#### Right 컬럼 제외하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8q51VXCr4sZ",
        "outputId": "02a268ee-b1ef-4966-e966-1dbcc43b3365"
      },
      "source": [
        "# Right 공정에 해당하는 컬럼\n",
        "col_right = [   'DB.N2.SCREEN.FLOW.RIGHT.1FI49012_PV',\n",
        "                 'DB.N2.SCREEN.FLOW.RIGHT.1FI49012_PV.1',\n",
        "                 'Right.edge',\n",
        "                 'TMP.TIN..BAY.1.RIGHT.1TI30202.PV',\n",
        "                 'TMP.TIN..BAY.5.RIGHT.1TI30206.PV',\n",
        "                 'TMP.TIN..BAY.7.RIGHT.1TI30208.PV',\n",
        "                 'TMP.TIN..BAY.10.RIGHT.1TI30210.PV',\n",
        "                 'TMP.GLASS..RIGHT.EXIT.1TIC30111.PV',\n",
        "                 'X.10.BAY.RIGHT.PRESSURE.1CLBAY10RIGHT_CPV',\n",
        "                 'X.1.BAY.RIGHT.PRESSURE.1CLBAY1RIGHT_CPV',\n",
        "                 'X.7.BAY.RIGHT.PRESSURE.1CLBAY7RIGHT_CPV',\n",
        "                 'RET.AMBIANT.RIGHT.TMP.1TI42603.PV',\n",
        "                 'BATH.AMBIENT.3.BAY.RIGHT.1TI31002_PV',\n",
        "                 'EXIT.LIP.PLATE.RIGHT.1TI30605.PV',\n",
        "                 'E.L.DB.RIGHT.N2.FLOW.1FI33502.PV',\n",
        "                 'DROSS.BOX.N2.BTM.HT1.R.1JI39006.PV',\n",
        "                 'DROSS.BOX.N2.BTM.HT..R..1JI39010.PV',\n",
        "                 'DROSSBOX.N2.SCN.R.1JI39012_PV',\n",
        "                 'HOOD.N2.HEATER.R..1JI39008.PV',\n",
        "                 'DDP.RIGHT.N2.H2.9..1FI33421.PV',\n",
        "                 'SPOUT.RIGHT.UPSTREAM.1FI33516.PV',\n",
        "                 'SPOUT.RIGHT.BOS.UPSTREAM.1FI33517.PV',\n",
        "                 'SPOUT.RIGHT.BOTTOM.1FI33518.PV',\n",
        "                 'SPOUT.RIGHT.TOP.1FI33519.PV',\n",
        "                 'LOR.1.R.Axis',\n",
        "                 'LOR.1.R.Hori',\n",
        "                 'LOR.2.R.Axis',\n",
        "                 'LOR.2.R.Hori',\n",
        "                 'LOR.3.R.Axis',\n",
        "                 'LOR.3.R.Hori',\n",
        "                 'r_tin_bay_1_5',\n",
        "                 'r_tin_bay_5_7',\n",
        "                 'r_tin_bay_7_10',\n",
        "                 'r_top_n.1_mean',\n",
        "                 'r_top_n.2_mean',\n",
        "                 'r_n.2_glass',\n",
        "                 'D_AB1_R_UL',\n",
        "                 'D_AB2_R_UL',\n",
        "                 'D_AB3_R_UL',\n",
        "                 'D_AB4_R_UL',\n",
        "                 'D_AB5_R_UL',\n",
        "                 'D_AB6_R_UL',\n",
        "                 'D_AB7_R_UL',\n",
        "                 'D_AB8_R_UL',\n",
        "                 'D_AB9_R_UL',\n",
        "                 'D_AB10_R_UL',\n",
        "                 'D_AB11_R_UL',\n",
        "                 'D_C1_R_UL',\n",
        "                 'D_C2_R_UL',\n",
        "                 'D_C3_R_UL',\n",
        "                 'D_C4_R_UL',\n",
        "                 'S_AB1_AB2_U_R',\n",
        "                 'S_AB1_AB2_L_R',\n",
        "                 'S_AB2_AB3_U_R',\n",
        "                 'S_AB2_AB3_L_R',\n",
        "                 'S_AB3_AB4_U_R',\n",
        "                 'S_AB3_AB4_L_R',\n",
        "                 'S_AB4_AB5_U_R',\n",
        "                 'S_AB4_AB5_L_R',\n",
        "                 'S_AB5_AB6_U_R',\n",
        "                 'S_AB5_AB6_L_R',\n",
        "                 'S_AB6_AB7_U_R',\n",
        "                 'S_AB6_AB7_L_R',\n",
        "                 'S_AB7_AB8_U_R',\n",
        "                 'S_AB7_AB8_L_R',\n",
        "                 'S_AB8_AB9_U_R',\n",
        "                 'S_AB8_AB9_L_R',\n",
        "                 'S_AB9_AB10_U_R',\n",
        "                 'S_AB9_AB10_L_R',\n",
        "                 'S_AB10_AB11_U_R',\n",
        "                 'S_AB10_AB11_L_R',\n",
        "                 'S_AB11_C1_U_R',\n",
        "                 'S_AB11_C1_L_R',\n",
        "                 'S_AB1_AB11_R',\n",
        "                 'S_AB11_AB7_R',\n",
        "                 'S_AB7_C4_R',\n",
        "                 'S_C1_C2_U_R',\n",
        "                 'S_C1_C2_L_R',\n",
        "                 'S_C2_C3_U_R',\n",
        "                 'S_C2_C3_L_R',\n",
        "                 'S_C3_C4_U_R',\n",
        "                 'S_C3_C4_L_R',\n",
        "                 'S_C4_RET_R',\n",
        "                 'S_RET_F_R',\n",
        "                 'STD_U_R',\n",
        "                 'STD_L_R',\n",
        "                 'STD_GLS_R',\n",
        "                 '투입.RIGHT.',\n",
        "                 'ROLLDOWN.폐기.RIGHT.',\n",
        "                 'ROLLDOWN.진공패드.폐기율..RIGHT.',\n",
        "                 '진공패드.폐기.RIGHT.']\n",
        "# 개수 확인\n",
        "len(col_right) # 91개"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIwNUeWhrXRG",
        "outputId": "0b269021-a5e7-4178-fa70-eaa25c12fc0d"
      },
      "source": [
        "# Right 컬럼 제외하기\n",
        "col_use = []\n",
        "for col in fact_data.columns:\n",
        "    if col not in col_right:\n",
        "       col_use.append(col)\n",
        "print(len(col_use)) # 146개\n",
        "\n",
        "# 데이터프레임 만들기\n",
        "fact_data = fact_data[col_use]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clfLbcOeQk1b"
      },
      "source": [
        "### 결측치 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRMcWlufsy9O",
        "outputId": "bc005a56-fc60-4a81-be76-fd24c4f8dd9e"
      },
      "source": [
        "# 결측치 찾기\n",
        "nan_data = fact_data.isnull().sum().sort_values(ascending=False)\n",
        "print(nan_data)\n",
        "## isnull() : 결측치를 찾아 True/False 리턴함.\n",
        "    # boolean 데이터타입은 숫자로 변환하면 True -> 1, False -> 0\n",
        "    # 여기서는 결측치가 있는 데이터는 1의 값을 갖게 됨\n",
        "## sum() : 컬럼별로 값을 모두 더함\n",
        "## sort_values() : 값을 크기별로 정렬함\n",
        "    # ascending=False 옵션을 주면 내림차순으로 정렬함"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROOF.HEATING.Zone52.1JIC31152.PV        8145\n",
            "ROOF.HEATING.Zone78.1JIC31178.PV        8145\n",
            "ROOF.HEATING.Zone76.1JIC31176.PV        8145\n",
            "LEHR.DRV.MTR..M19.2.CUR.1WII40135.PV    8145\n",
            "DCS_Offset_RPM_M13.1WOS45113_PV         8145\n",
            "                                        ... \n",
            "ROOF.HEATING.Zone10.1JIC31110.PV           0\n",
            "ROOF.HEATING.Zone.9.1JIC31109.PV.1         0\n",
            "ROOF.HEATING.Zone.8.1JIC31108.PV.1         0\n",
            "ROOF.HEATING.Zone.7.1JIC31107.PV.1         0\n",
            "LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101          0\n",
            "Length: 741, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFsvINL23Llx",
        "outputId": "4e718c8f-3f48-4287-a17f-59d6c6dbbb28"
      },
      "source": [
        "# 이때 결측치 개수 컬럼은 시리즈 타입이므로 슬라이싱 됨. nan 개수 상위 20개 정도 살펴보자.\n",
        "print(type(nan_data))\n",
        "\n",
        "# 조회 결과, 7개 컬럼은 전체 8145개의 행이 모두 결측치임. 데이터가 없으므로 삭제.\n",
        "print(nan_data[:20])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "ROOF.HEATING.Zone52.1JIC31152.PV        8145\n",
            "ROOF.HEATING.Zone78.1JIC31178.PV        8145\n",
            "ROOF.HEATING.Zone76.1JIC31176.PV        8145\n",
            "LEHR.DRV.MTR..M19.2.CUR.1WII40135.PV    8145\n",
            "DCS_Offset_RPM_M13.1WOS45113_PV         8145\n",
            "DCS_Offset_RPM_M14.1WOS45114_PV         8145\n",
            "UPPER.RET..Z218.TMP.1TIC42601.PV        8145\n",
            "LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101.1        1\n",
            "LOWER.C3..Z193TMP.1TIC42454.PV             1\n",
            "DB.HEAT.BTM.LEFT.2.TMP.1TI40316.PV         1\n",
            "DB.HEAT.TOP.3.2.TMP.1TI40310.PV            1\n",
            "DB.HEAT.TOP.2.2.TMP.1TI40309.PV            1\n",
            "DB.HEAT.TOP.1.2.TMP.1TI40308.PV            1\n",
            "DB.HEAT.TOP.7.1.TMP.1TI40307.PV            1\n",
            "DB.HEAT.TOP.6.1.TMP.1TI40306.PV            1\n",
            "LOWER.C4..Z207.TMP.1TIC42554.PV            1\n",
            "LEHR.DRV.MTR..M4.1.SPD.1WSI40104.1         1\n",
            "LIFT.OUT.ROL.MTR.M2.SPD.1WSI40102.1        1\n",
            "LIFT.OUT.ROL.MTR.M3.SPD.1WSI40103.1        1\n",
            "DROSS.BOX.N2.BTM.HT..L..1JI39009.PV        1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5uwwSPm5Taa",
        "outputId": "ce39195b-cb5b-46ca-b85e-b2b99596f31d"
      },
      "source": [
        "# 전체 행이 결측치인 컬럼을 찾고 삭제하기\n",
        "\n",
        "# 1. 전체 행이 결측치인 컬럼을 찾기\n",
        "print(nan_data[nan_data.values == fact_data.shape[0]].index.tolist())\n",
        "    # nan_data에서 다음 조건에 해당하는 컬럼을 찾음\n",
        "        # nan_data.values : nan_data를 데이터 배열로 만들어줌\n",
        "        # fact_data.shape -> (행 개수, 열 개수)\n",
        "            # fact_data.shape[0]는 fact_data 행의 개수임\n",
        "    # .index : 그때의 컬럼이름(여기선 인덱스)을 추출함\n",
        "    # .tolist() : 데이터를 리스트 타입으로 변환함\n",
        "\n",
        "# 2. 해당 컬럼삭제하기\n",
        "fact_data.drop(nan_data[nan_data.values == fact_data.shape[0]].index.tolist(), axis=1, inplace=True)\n",
        "    # inplace=True : drop 수행한 결과를 fact_data에 반영할지 여부 설정\n",
        "\n",
        "# 3. 확인 - 컬럼 수가 줄어들었나 확인 (840개 -> 833개)\n",
        "fact_data.info()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ROOF.HEATING.Zone52.1JIC31152.PV', 'ROOF.HEATING.Zone78.1JIC31178.PV', 'ROOF.HEATING.Zone76.1JIC31176.PV', 'LEHR.DRV.MTR..M19.2.CUR.1WII40135.PV', 'DCS_Offset_RPM_M13.1WOS45113_PV', 'DCS_Offset_RPM_M14.1WOS45114_PV', 'UPPER.RET..Z218.TMP.1TIC42601.PV']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8145 entries, 2016-01-01 07 to 2016-12-31 23\n",
            "Columns: 734 entries, LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101 to ROLLDOWN.진공패드.폐기율..전체.\n",
            "dtypes: float64(734)\n",
            "memory usage: 45.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUomKUukOiUL",
        "outputId": "01c90095-b42b-4e75-8bbb-558adf697e70"
      },
      "source": [
        "# 그 외 결측치 처리\n",
        "# 남은 결측치는 ffill로 채워주자\n",
        "# 이 데이터는 1시간마다 측정한 센서 데이터이므로 전체 컬럼에 대한 평균보다는 이전 행의 값으로 결측치를 처리하는 것이 적절함\n",
        "fact_data.fillna(method = 'ffill', inplace=True)\n",
        "    # inplace=True : fillna 수행한 결과를 fact_data에 반영할지 여부 설정\n",
        "\n",
        "# 확인\n",
        "fact_data.isnull().sum().sort_values()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101     0\n",
              "ROOF.HEATING.Zone.5.1JIC31105.PV      0\n",
              "ROOF.HEATING.Zone.6.1JIC31106.PV      0\n",
              "ROOF.HEATING.Zone.7.1JIC31107.PV.1    0\n",
              "ROOF.HEATING.Zone.8.1JIC31108.PV.1    0\n",
              "                                     ..\n",
              "LOWER.C3..Z196.TMP.1TIC42457.PV       0\n",
              "UPPER.C4..Z197.TMP.1TIC42501.PV       0\n",
              "UPPER.C4..Z198.TMP.1TIC42502.PV       0\n",
              "UPPER.C4..Z200.TMP.1TIC42504.PV       0\n",
              "ROLLDOWN.진공패드.폐기율..전체.                0\n",
              "Length: 734, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hXEeyhMQwA6"
      },
      "source": [
        "### 분산 0인 데이터 제거\n",
        "- 분산이 0인 데이터를 제거하는 이유?\n",
        "    - 어떤 피처의 분산이 0이라는 것은 그 피처의 데이터가 모든 행에 대해 거의 변하지 않은 것을 의미함\n",
        "    - 어떤 경우에도 같은 값을 내는 컬럼이 불량률에 영향을 주고 있다고 보기 어려움\n",
        "- 수행 방법\n",
        "    - 방법1 : sklearn의 VarianceThreshold 사용\n",
        "    - 방법2 : var() 사용\n",
        "- 결과\n",
        "    - 컬럼수 : 831->818\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ_f0TGBQxsK"
      },
      "source": [
        "# 방법1\n",
        "#from sklearn.feature_selection import VarianceThreshold\n",
        "#selector = VarianceThreshold()\n",
        "#df = selector.fit_transform(fact_data)\n",
        "#print(df.shape)\n",
        "#df"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOcaMZJvRgbK",
        "outputId": "7b95175a-a1ef-4851-953c-cf413940fb3c"
      },
      "source": [
        "# 방법 2\n",
        "# 분산 구하기\n",
        "df_var = fact_data.var()    # 시리즈\n",
        "# 확인\n",
        "print(df_var.describe())\n",
        "\n",
        "# 분산이 0에 수렴하는 컬럼 확인\n",
        "## 10e-10 이하면 0에 수렴하는 값으로 간주함\n",
        "print(df_var[df_var.values <= 10e-10])\n",
        "\n",
        "# 삭제\n",
        "fact_data.drop(df_var[df_var.values <= 10e-10].index, axis=1, inplace=True)\n",
        "\n",
        "# 컬럼 수 확인\n",
        "print(len(fact_data.columns))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    7.340000e+02\n",
            "mean     1.049214e+00\n",
            "std      1.125586e+00\n",
            "min      7.538541e-27\n",
            "25%      1.000223e+00\n",
            "50%      1.000674e+00\n",
            "75%      1.000816e+00\n",
            "max      2.248774e+01\n",
            "dtype: float64\n",
            "LEHR.DRV.MTR..M4.2.CUR.1WII40105.PV     7.538541e-27\n",
            "LEHR.DRV.MTR..M9.1.CUR.1WII40114.PV     7.538541e-27\n",
            "LEHR.DRV.MTR..M9.2.CUR.1WII40115.PV     7.538541e-27\n",
            "LEHR.DRV.MTR..M10.1.CUR.1WII40116.PV    7.538541e-27\n",
            "LEHR.DRV.MTR..M14.1.CUR.1WII40124.PV    7.538541e-27\n",
            "LEHR.DRV.MTR..M17.2.CUR.1WII40131.PV    7.538541e-27\n",
            "TMP.TIN..BAY.4.LEFT.1TI30203.PV         7.538541e-27\n",
            "dtype: float64\n",
            "727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8pQoi5qQqva"
      },
      "source": [
        "### 피처 간 상관관계 높은 피처 제거\n",
        "- 상관관계 : 피처 간의 종속된 정도\n",
        "- 상관관계가 높은 피처를 제거하는 이유?\n",
        "    - 두 피처 간의 상관관계가 높다는 것은, 하나의 피처 값이 다른 피처의 값에 큰 영향을 주고있음을 의미함\n",
        "    - 두 피처는 동일한 원인에 기인하여 변하는 것으로 추측할 수 있음\n",
        "    - 이를 제거하지 않고 두면 사실상 같은 의미인 데이터가 모델링에 여러 번 반영됨\n",
        "    - 사실상 종속관계에 있는 피처들이 모델링에 크게 기여하는 것과 같음\n",
        "    - 모델링에 영향을 미치는 원인들이 모두 비슷한 중요도로 반영되게 하려면 종속성이 낮은 피처들만을 이용하여 모델을 만드는 것이 타당함\n",
        "- 여기서는 피처 간 상관계수의 절대값이 0.9 이상인 경우를 종속된 것으로 봄\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lHjOEdh9ATz",
        "outputId": "617b413c-cb9c-4d77-cebb-54ab34cdfb90"
      },
      "source": [
        "# 모든 컬럼에 대해 상관계수를 구하고 상관계수가 0.9 이상인 컬럼 중 1개만 남기고 모두 제거\n",
        "\n",
        "# 모든 컬럼에 대해 상관계수의 절대값 구하기\n",
        "corr_arr = abs(fact_data.corr())\n",
        "\n",
        "# 상관계수가 0.9 이상인 컬럼 중 1개만 남기고 모두 제거\n",
        "del_list = []\n",
        "for i, col in enumerate(corr_arr.columns):\n",
        "    for j in range(len(corr_arr.index)):\n",
        "        if i == j:\n",
        "            continue\n",
        "        elif corr_arr.index[i] in del_list:           \n",
        "            break\n",
        "        # print(i, j, corr_arr.index[j], np.abs(corr_arr.iloc[j,i]))\n",
        "        if np.abs(corr_arr.iloc[j,i]) >= 0.9:\n",
        "            del_list.append(corr_arr.index[j])\n",
        "            # print(corr_arr.index[j], '-->', corr_arr.index[i])\n",
        "# 확인\n",
        "len(del_list)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68-UpKrfVXDG",
        "outputId": "91aefe43-f25a-4261-e93e-afb8db5973e4"
      },
      "source": [
        "# del_list에 있는 컬럼은 제외\n",
        "total_col = fact_data.columns.tolist()\n",
        "col_remain = []\n",
        "for c in total_col:\n",
        "    if c not in del_list:\n",
        "        col_remain.append(c)\n",
        "len(col_remain)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAJpOIcPVe6m",
        "outputId": "6e688849-86d1-437c-9120-c223a3008b31"
      },
      "source": [
        "# 저장\n",
        "fact_data = fact_data[col_remain]\n",
        "fact_data.info()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8145 entries, 2016-01-01 07 to 2016-12-31 23\n",
            "Columns: 325 entries, LIFT.OUT.ROL.MTR.M1.SPD.1WSI40101 to 폐기율...\n",
            "dtypes: float64(325)\n",
            "memory usage: 20.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmof_MJRV9UI"
      },
      "source": [
        "### (안함) VIF > 30 이상의 피처 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkXpYVSgVzig"
      },
      "source": [
        "# 화이팅"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu6CzEAWWEFw"
      },
      "source": [
        "## 분류 모델링을 위한 전처리\n",
        "- 325개의 컬럼으로 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5xhPDJFs8xY"
      },
      "source": [
        "### 스케일링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB40kgyts8JQ",
        "outputId": "cfc024c6-e2d2-46ce-ad8b-e14b0e26f269"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(fact_data)\n",
        "fact_data_scaled = scaler.transform(fact_data)\n",
        "\n",
        "\n",
        "# 데이터 범위 확인\n",
        "print(\"스케일링한 데이터 최소값:\", fact_data_scaled.min())\n",
        "print(\"스케일링한 데이터 최대값:\", fact_data_scaled.max())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "스케일링한 데이터 최소값: 0.0\n",
            "스케일링한 데이터 최대값: 1.0000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpN-xs6ntJYP"
      },
      "source": [
        "### PCA 수행하여 주성분 몇 개가 적절한지 조사\n",
        "- 적당한 n_components 개수 정하기\n",
        "- 방법1\n",
        "    - 설명변수가 급감하는 때의 주성분 인덱스를 찾음\n",
        "    - 이 경우 최소한의 주성분 개수로 전체 데이터의 경향을 설명할 수 있음\n",
        "- 방법2\n",
        "    - 설명변수 비율의 누적합이 0.95일 때의 주성분 개수로 선택할 수 있음\n",
        "    - 이 경우 전체 데이터의 95%를 설명하기 위한 주성분 개수를 구하는 것과 같음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe3_M34vtOWe",
        "outputId": "9eced20c-4d8e-417e-f85b-0cf16f299847"
      },
      "source": [
        "# PCA 수행\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 피처개수 146개만큼 주성분을 뽑아보자\n",
        "pca = PCA(n_components=len(fact_data.columns))\n",
        "\n",
        "# 스케일링한 값을 넣고 fit() 과 transform()을 호출해 PCA 변환 데이터 리턴\n",
        "pca.fit(fact_data_scaled)\n",
        "fact_data_pca = pca.transform(fact_data_scaled)\n",
        "\n",
        "# PCA 수행 후 데이터 확인\n",
        "print(\"데이터 구조\", fact_data_pca.shape)\n",
        "\n",
        "# 설명변수\n",
        "## 각 주성분이 전체 데이터 집합을 얼마나 잘 설명하는지 나타내는 값\n",
        "print(\"- 각 주성분의 설명변수 :\", pca.explained_variance_[:4])\n",
        "# 설명변수 비율\n",
        "## 전체 주성분의 설명변수 비율 합은 1(100%)\n",
        "print(\"- 각 주성분의 설명변수 비율 :\", pca.explained_variance_ratio_[:4])\n",
        "# 주성분 행렬\n",
        "print('- singular value :', pca.singular_values_[:4])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 구조 (8145, 325)\n",
            "- 각 주성분의 설명변수 : [2.36102173 1.07909775 0.732532   0.39970418]\n",
            "- 각 주성분의 설명변수 비율 : [0.32151169 0.14694593 0.09975241 0.05442964]\n",
            "- singular value : [138.66564465  93.74525098  77.23820704  57.05427987]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "U0VIaQbwtXoe",
        "outputId": "b605168e-056e-41a4-c572-98c54783a757"
      },
      "source": [
        "# PCA 수행 결과를 데이터프레임으로 만들어서 확인\n",
        "\n",
        "# 컬럼이름 붙이기\n",
        "pca_columns_name = [f\"pca{num+1}\" for num in range(fact_data.shape[1])]\n",
        "# 데이터프레임 만들기\n",
        "pca_df = pd.DataFrame(fact_data_pca, columns = pca_columns_name, index=fact_data.index)\n",
        "pca_df.info()\n",
        "pca_df.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8145 entries, 2016-01-01 07 to 2016-12-31 23\n",
            "Columns: 325 entries, pca1 to pca325\n",
            "dtypes: float64(325)\n",
            "memory usage: 20.3+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca1</th>\n",
              "      <th>pca2</th>\n",
              "      <th>pca3</th>\n",
              "      <th>pca4</th>\n",
              "      <th>pca5</th>\n",
              "      <th>pca6</th>\n",
              "      <th>pca7</th>\n",
              "      <th>pca8</th>\n",
              "      <th>pca9</th>\n",
              "      <th>pca10</th>\n",
              "      <th>pca11</th>\n",
              "      <th>pca12</th>\n",
              "      <th>pca13</th>\n",
              "      <th>pca14</th>\n",
              "      <th>pca15</th>\n",
              "      <th>pca16</th>\n",
              "      <th>pca17</th>\n",
              "      <th>pca18</th>\n",
              "      <th>pca19</th>\n",
              "      <th>pca20</th>\n",
              "      <th>pca21</th>\n",
              "      <th>pca22</th>\n",
              "      <th>pca23</th>\n",
              "      <th>pca24</th>\n",
              "      <th>pca25</th>\n",
              "      <th>pca26</th>\n",
              "      <th>pca27</th>\n",
              "      <th>pca28</th>\n",
              "      <th>pca29</th>\n",
              "      <th>pca30</th>\n",
              "      <th>pca31</th>\n",
              "      <th>pca32</th>\n",
              "      <th>pca33</th>\n",
              "      <th>pca34</th>\n",
              "      <th>pca35</th>\n",
              "      <th>pca36</th>\n",
              "      <th>pca37</th>\n",
              "      <th>pca38</th>\n",
              "      <th>pca39</th>\n",
              "      <th>pca40</th>\n",
              "      <th>...</th>\n",
              "      <th>pca286</th>\n",
              "      <th>pca287</th>\n",
              "      <th>pca288</th>\n",
              "      <th>pca289</th>\n",
              "      <th>pca290</th>\n",
              "      <th>pca291</th>\n",
              "      <th>pca292</th>\n",
              "      <th>pca293</th>\n",
              "      <th>pca294</th>\n",
              "      <th>pca295</th>\n",
              "      <th>pca296</th>\n",
              "      <th>pca297</th>\n",
              "      <th>pca298</th>\n",
              "      <th>pca299</th>\n",
              "      <th>pca300</th>\n",
              "      <th>pca301</th>\n",
              "      <th>pca302</th>\n",
              "      <th>pca303</th>\n",
              "      <th>pca304</th>\n",
              "      <th>pca305</th>\n",
              "      <th>pca306</th>\n",
              "      <th>pca307</th>\n",
              "      <th>pca308</th>\n",
              "      <th>pca309</th>\n",
              "      <th>pca310</th>\n",
              "      <th>pca311</th>\n",
              "      <th>pca312</th>\n",
              "      <th>pca313</th>\n",
              "      <th>pca314</th>\n",
              "      <th>pca315</th>\n",
              "      <th>pca316</th>\n",
              "      <th>pca317</th>\n",
              "      <th>pca318</th>\n",
              "      <th>pca319</th>\n",
              "      <th>pca320</th>\n",
              "      <th>pca321</th>\n",
              "      <th>pca322</th>\n",
              "      <th>pca323</th>\n",
              "      <th>pca324</th>\n",
              "      <th>pca325</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dat...date.name.</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-01 07</th>\n",
              "      <td>3.452527</td>\n",
              "      <td>1.533809</td>\n",
              "      <td>1.323886</td>\n",
              "      <td>1.542712</td>\n",
              "      <td>0.183121</td>\n",
              "      <td>0.656539</td>\n",
              "      <td>-0.011691</td>\n",
              "      <td>0.198646</td>\n",
              "      <td>0.792417</td>\n",
              "      <td>0.933732</td>\n",
              "      <td>0.689587</td>\n",
              "      <td>-0.539740</td>\n",
              "      <td>-0.584063</td>\n",
              "      <td>-0.570702</td>\n",
              "      <td>0.049210</td>\n",
              "      <td>-0.050188</td>\n",
              "      <td>-0.918162</td>\n",
              "      <td>0.469422</td>\n",
              "      <td>-0.033838</td>\n",
              "      <td>0.015427</td>\n",
              "      <td>0.032161</td>\n",
              "      <td>-0.335349</td>\n",
              "      <td>-0.234412</td>\n",
              "      <td>-0.034332</td>\n",
              "      <td>-0.268557</td>\n",
              "      <td>0.450278</td>\n",
              "      <td>-0.178547</td>\n",
              "      <td>-0.002137</td>\n",
              "      <td>0.102945</td>\n",
              "      <td>-0.098039</td>\n",
              "      <td>0.044414</td>\n",
              "      <td>0.134852</td>\n",
              "      <td>0.184106</td>\n",
              "      <td>0.464864</td>\n",
              "      <td>-0.040969</td>\n",
              "      <td>0.071232</td>\n",
              "      <td>0.072646</td>\n",
              "      <td>-0.050108</td>\n",
              "      <td>-0.312152</td>\n",
              "      <td>0.189300</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>0.000627</td>\n",
              "      <td>0.000355</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>0.000395</td>\n",
              "      <td>-0.000748</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>-0.000101</td>\n",
              "      <td>-0.000941</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>-0.000317</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>-0.000271</td>\n",
              "      <td>-0.000879</td>\n",
              "      <td>-0.000116</td>\n",
              "      <td>-0.000007</td>\n",
              "      <td>-2.721801e-09</td>\n",
              "      <td>-3.816269e-11</td>\n",
              "      <td>3.839190e-11</td>\n",
              "      <td>-4.212336e-11</td>\n",
              "      <td>8.473320e-12</td>\n",
              "      <td>4.159003e-11</td>\n",
              "      <td>4.358408e-13</td>\n",
              "      <td>-5.512232e-11</td>\n",
              "      <td>-1.247813e-10</td>\n",
              "      <td>-5.828093e-11</td>\n",
              "      <td>7.350097e-12</td>\n",
              "      <td>-2.876308e-11</td>\n",
              "      <td>1.517614e-11</td>\n",
              "      <td>8.517374e-12</td>\n",
              "      <td>-1.087013e-11</td>\n",
              "      <td>-2.806739e-12</td>\n",
              "      <td>3.868135e-11</td>\n",
              "      <td>-1.395923e-11</td>\n",
              "      <td>-3.400296e-11</td>\n",
              "      <td>2.539618e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 08</th>\n",
              "      <td>3.437189</td>\n",
              "      <td>1.512892</td>\n",
              "      <td>1.329426</td>\n",
              "      <td>1.540556</td>\n",
              "      <td>0.155383</td>\n",
              "      <td>0.625875</td>\n",
              "      <td>0.025668</td>\n",
              "      <td>0.207212</td>\n",
              "      <td>0.792517</td>\n",
              "      <td>0.946555</td>\n",
              "      <td>0.718398</td>\n",
              "      <td>-0.539722</td>\n",
              "      <td>-0.581252</td>\n",
              "      <td>-0.554636</td>\n",
              "      <td>-0.031841</td>\n",
              "      <td>-0.039051</td>\n",
              "      <td>-0.908817</td>\n",
              "      <td>0.440760</td>\n",
              "      <td>-0.036983</td>\n",
              "      <td>0.034583</td>\n",
              "      <td>-0.008182</td>\n",
              "      <td>-0.374090</td>\n",
              "      <td>-0.208744</td>\n",
              "      <td>-0.022218</td>\n",
              "      <td>-0.273319</td>\n",
              "      <td>0.461592</td>\n",
              "      <td>-0.186129</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>0.052902</td>\n",
              "      <td>-0.044170</td>\n",
              "      <td>0.069446</td>\n",
              "      <td>0.096062</td>\n",
              "      <td>0.110267</td>\n",
              "      <td>0.328989</td>\n",
              "      <td>0.013370</td>\n",
              "      <td>0.016166</td>\n",
              "      <td>0.064801</td>\n",
              "      <td>-0.037249</td>\n",
              "      <td>-0.229233</td>\n",
              "      <td>0.208264</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000836</td>\n",
              "      <td>0.000311</td>\n",
              "      <td>-0.000058</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>-0.000572</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>-0.000522</td>\n",
              "      <td>0.000571</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>-0.000108</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>-0.000369</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>-0.000294</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>-3.066720e-09</td>\n",
              "      <td>1.113339e-09</td>\n",
              "      <td>2.937498e-11</td>\n",
              "      <td>5.103251e-11</td>\n",
              "      <td>3.789058e-12</td>\n",
              "      <td>4.492680e-11</td>\n",
              "      <td>-7.541727e-11</td>\n",
              "      <td>2.976486e-11</td>\n",
              "      <td>3.592476e-11</td>\n",
              "      <td>-1.016878e-11</td>\n",
              "      <td>-5.479823e-11</td>\n",
              "      <td>-3.139265e-11</td>\n",
              "      <td>-1.401166e-11</td>\n",
              "      <td>2.175264e-11</td>\n",
              "      <td>-4.173688e-11</td>\n",
              "      <td>-2.664043e-11</td>\n",
              "      <td>-1.751602e-13</td>\n",
              "      <td>-2.453915e-11</td>\n",
              "      <td>9.139483e-12</td>\n",
              "      <td>2.079229e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 09</th>\n",
              "      <td>3.464792</td>\n",
              "      <td>1.526558</td>\n",
              "      <td>1.338462</td>\n",
              "      <td>1.575942</td>\n",
              "      <td>0.159724</td>\n",
              "      <td>0.613717</td>\n",
              "      <td>0.032359</td>\n",
              "      <td>0.147726</td>\n",
              "      <td>0.823774</td>\n",
              "      <td>0.942204</td>\n",
              "      <td>0.717249</td>\n",
              "      <td>-0.556960</td>\n",
              "      <td>-0.563052</td>\n",
              "      <td>-0.504648</td>\n",
              "      <td>0.007678</td>\n",
              "      <td>0.007613</td>\n",
              "      <td>-0.895947</td>\n",
              "      <td>0.382570</td>\n",
              "      <td>-0.000814</td>\n",
              "      <td>0.018554</td>\n",
              "      <td>0.027737</td>\n",
              "      <td>-0.303451</td>\n",
              "      <td>-0.273145</td>\n",
              "      <td>-0.006438</td>\n",
              "      <td>-0.171159</td>\n",
              "      <td>0.422955</td>\n",
              "      <td>-0.211508</td>\n",
              "      <td>0.057228</td>\n",
              "      <td>-0.011271</td>\n",
              "      <td>0.028329</td>\n",
              "      <td>0.047506</td>\n",
              "      <td>0.018358</td>\n",
              "      <td>0.048855</td>\n",
              "      <td>0.453669</td>\n",
              "      <td>0.068625</td>\n",
              "      <td>0.059105</td>\n",
              "      <td>0.101009</td>\n",
              "      <td>-0.069568</td>\n",
              "      <td>-0.265144</td>\n",
              "      <td>0.201140</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000201</td>\n",
              "      <td>-0.000553</td>\n",
              "      <td>-0.000991</td>\n",
              "      <td>-0.000515</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>0.000359</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>-0.000237</td>\n",
              "      <td>-0.001093</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>-0.000661</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>0.000602</td>\n",
              "      <td>-0.000522</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>-0.000134</td>\n",
              "      <td>-0.000007</td>\n",
              "      <td>9.377311e-11</td>\n",
              "      <td>4.111950e-10</td>\n",
              "      <td>4.609113e-11</td>\n",
              "      <td>-6.280158e-11</td>\n",
              "      <td>-1.905137e-11</td>\n",
              "      <td>9.382512e-11</td>\n",
              "      <td>-1.101218e-11</td>\n",
              "      <td>-1.836513e-11</td>\n",
              "      <td>-2.992896e-11</td>\n",
              "      <td>-2.068506e-11</td>\n",
              "      <td>-2.010470e-11</td>\n",
              "      <td>-3.051983e-11</td>\n",
              "      <td>2.037900e-11</td>\n",
              "      <td>-2.398444e-11</td>\n",
              "      <td>4.358677e-12</td>\n",
              "      <td>6.446795e-12</td>\n",
              "      <td>-2.890889e-11</td>\n",
              "      <td>1.787658e-11</td>\n",
              "      <td>1.679081e-11</td>\n",
              "      <td>-1.388207e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 10</th>\n",
              "      <td>3.467155</td>\n",
              "      <td>1.540072</td>\n",
              "      <td>1.328730</td>\n",
              "      <td>1.555071</td>\n",
              "      <td>0.125659</td>\n",
              "      <td>0.643282</td>\n",
              "      <td>0.103772</td>\n",
              "      <td>0.133418</td>\n",
              "      <td>0.757122</td>\n",
              "      <td>0.941931</td>\n",
              "      <td>0.779887</td>\n",
              "      <td>-0.582086</td>\n",
              "      <td>-0.596052</td>\n",
              "      <td>-0.527201</td>\n",
              "      <td>-0.011283</td>\n",
              "      <td>-0.032384</td>\n",
              "      <td>-0.928584</td>\n",
              "      <td>0.431864</td>\n",
              "      <td>-0.042126</td>\n",
              "      <td>0.018688</td>\n",
              "      <td>-0.009855</td>\n",
              "      <td>-0.350683</td>\n",
              "      <td>-0.220539</td>\n",
              "      <td>-0.049981</td>\n",
              "      <td>-0.278155</td>\n",
              "      <td>0.482162</td>\n",
              "      <td>-0.181093</td>\n",
              "      <td>0.012355</td>\n",
              "      <td>0.074217</td>\n",
              "      <td>-0.040835</td>\n",
              "      <td>0.060803</td>\n",
              "      <td>0.051709</td>\n",
              "      <td>0.120123</td>\n",
              "      <td>0.364597</td>\n",
              "      <td>0.049702</td>\n",
              "      <td>0.030957</td>\n",
              "      <td>0.092043</td>\n",
              "      <td>-0.033457</td>\n",
              "      <td>-0.256902</td>\n",
              "      <td>0.213552</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000274</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000826</td>\n",
              "      <td>-0.000277</td>\n",
              "      <td>-0.000479</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>-0.000291</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>-0.000086</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>-0.000631</td>\n",
              "      <td>0.000419</td>\n",
              "      <td>-0.000577</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000706</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>3.453179e-09</td>\n",
              "      <td>-4.401535e-10</td>\n",
              "      <td>-4.367124e-11</td>\n",
              "      <td>5.530068e-11</td>\n",
              "      <td>2.335987e-11</td>\n",
              "      <td>-4.207952e-11</td>\n",
              "      <td>6.888327e-11</td>\n",
              "      <td>-7.770148e-11</td>\n",
              "      <td>-4.086971e-11</td>\n",
              "      <td>7.277482e-11</td>\n",
              "      <td>-6.885167e-12</td>\n",
              "      <td>5.354312e-11</td>\n",
              "      <td>-3.867547e-12</td>\n",
              "      <td>-1.034372e-11</td>\n",
              "      <td>1.751242e-12</td>\n",
              "      <td>4.565548e-11</td>\n",
              "      <td>3.749349e-11</td>\n",
              "      <td>-4.206563e-11</td>\n",
              "      <td>2.533172e-12</td>\n",
              "      <td>-5.487311e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01 11</th>\n",
              "      <td>3.532537</td>\n",
              "      <td>1.547835</td>\n",
              "      <td>1.335525</td>\n",
              "      <td>1.567419</td>\n",
              "      <td>0.108039</td>\n",
              "      <td>0.703388</td>\n",
              "      <td>0.153403</td>\n",
              "      <td>0.011895</td>\n",
              "      <td>0.801740</td>\n",
              "      <td>0.883668</td>\n",
              "      <td>0.750729</td>\n",
              "      <td>-0.606428</td>\n",
              "      <td>-0.618410</td>\n",
              "      <td>-0.456236</td>\n",
              "      <td>0.026391</td>\n",
              "      <td>0.044970</td>\n",
              "      <td>-0.843589</td>\n",
              "      <td>0.380932</td>\n",
              "      <td>0.072108</td>\n",
              "      <td>-0.052091</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>-0.313660</td>\n",
              "      <td>-0.250748</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.184872</td>\n",
              "      <td>0.397042</td>\n",
              "      <td>-0.209460</td>\n",
              "      <td>0.124054</td>\n",
              "      <td>-0.008778</td>\n",
              "      <td>-0.009306</td>\n",
              "      <td>0.065415</td>\n",
              "      <td>-0.016898</td>\n",
              "      <td>-0.002687</td>\n",
              "      <td>0.459291</td>\n",
              "      <td>0.215382</td>\n",
              "      <td>0.085711</td>\n",
              "      <td>0.165011</td>\n",
              "      <td>-0.018140</td>\n",
              "      <td>-0.250387</td>\n",
              "      <td>0.128577</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000823</td>\n",
              "      <td>-0.000371</td>\n",
              "      <td>0.000606</td>\n",
              "      <td>-0.000784</td>\n",
              "      <td>-0.001357</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>-0.000389</td>\n",
              "      <td>-0.000460</td>\n",
              "      <td>-0.000256</td>\n",
              "      <td>-0.000034</td>\n",
              "      <td>-0.000201</td>\n",
              "      <td>-0.000270</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>-0.000454</td>\n",
              "      <td>-0.000268</td>\n",
              "      <td>-0.000373</td>\n",
              "      <td>-0.000224</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>5.080404e-10</td>\n",
              "      <td>-4.536461e-10</td>\n",
              "      <td>-5.705979e-11</td>\n",
              "      <td>3.520217e-11</td>\n",
              "      <td>4.230002e-11</td>\n",
              "      <td>5.876342e-12</td>\n",
              "      <td>1.354293e-11</td>\n",
              "      <td>1.707602e-11</td>\n",
              "      <td>3.409157e-11</td>\n",
              "      <td>-2.298813e-11</td>\n",
              "      <td>-8.672905e-12</td>\n",
              "      <td>-2.559606e-11</td>\n",
              "      <td>2.134911e-11</td>\n",
              "      <td>4.434214e-11</td>\n",
              "      <td>2.679883e-11</td>\n",
              "      <td>1.598345e-11</td>\n",
              "      <td>-6.005890e-12</td>\n",
              "      <td>-1.548088e-11</td>\n",
              "      <td>-1.986845e-11</td>\n",
              "      <td>9.732292e-12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 325 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      pca1      pca2  ...        pca324        pca325\n",
              "dat...date.name.                      ...                            \n",
              "2016-01-01 07     3.452527  1.533809  ... -3.400296e-11  2.539618e-11\n",
              "2016-01-01 08     3.437189  1.512892  ...  9.139483e-12  2.079229e-11\n",
              "2016-01-01 09     3.464792  1.526558  ...  1.679081e-11 -1.388207e-11\n",
              "2016-01-01 10     3.467155  1.540072  ...  2.533172e-12 -5.487311e-12\n",
              "2016-01-01 11     3.532537  1.547835  ... -1.986845e-11  9.732292e-12\n",
              "\n",
              "[5 rows x 325 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syNYcotaw2Am"
      },
      "source": [
        "#### n_components 개수 정하기 : elbow 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "f9Xn9LwUuEi3",
        "outputId": "7ab6ea17-1af1-47eb-8061-12892b062d32"
      },
      "source": [
        "# 방법1\n",
        "# Scree Plot 그리기\n",
        "# x축 : n_components 수\n",
        "# y축 : 설명변수\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(pca.explained_variance_, marker='o', c='blue')\n",
        "plt.xlabel(\"n_components\", fontsize=20)\n",
        "plt.ylabel(\"explained_variance_\", fontsize=20)\n",
        "# Elbow(그래프가 급격히 꺾이는 지점) 확인\n",
        "# n_components = 7, 즉 주성분 7개로 전체 데이터를 설명할 수 있을 것으로 보임"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'explained_variance_')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thwvssrpw6yu"
      },
      "source": [
        "#### n_components 개수 정하기 : 전체 데이터의 90%를 설명하는 피처 개수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2t1VOacuY5_",
        "outputId": "780ab977-4cb4-4ad4-d9d7-040bd1462bfe"
      },
      "source": [
        "explain_cumsum = 0\n",
        "for feature_num in range(pca.n_components):\n",
        "    if explain_cumsum <= 0.9:\n",
        "        explain_cumsum += pca.explained_variance_ratio_[i]\n",
        "    else:\n",
        "        break\n",
        "print(\"주성분 {}개로 전체 데이터의 {}%를 설명함\".format(feature_num, (explain_cumsum*100).round(3)))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "주성분 203개로 전체 데이터의 90.057%를 설명함\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "L3h2SaSJuRqX",
        "outputId": "e74062f6-196d-406d-c5b0-3b16fb50ded7"
      },
      "source": [
        "# 데이터프레임으로 보기\n",
        "result = pd.DataFrame({'설명가능한 분산 비율(고윳값)':pca.explained_variance_, '기여율':pca.explained_variance_ratio_},\n",
        "                      index=pca_columns_name)\n",
        "result[:10]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>설명가능한 분산 비율(고윳값)</th>\n",
              "      <th>기여율</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pca1</th>\n",
              "      <td>2.361022</td>\n",
              "      <td>0.321512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca2</th>\n",
              "      <td>1.079098</td>\n",
              "      <td>0.146946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca3</th>\n",
              "      <td>0.732532</td>\n",
              "      <td>0.099752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca4</th>\n",
              "      <td>0.399704</td>\n",
              "      <td>0.054430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca5</th>\n",
              "      <td>0.308124</td>\n",
              "      <td>0.041959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca6</th>\n",
              "      <td>0.232358</td>\n",
              "      <td>0.031641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca7</th>\n",
              "      <td>0.169052</td>\n",
              "      <td>0.023021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca8</th>\n",
              "      <td>0.152798</td>\n",
              "      <td>0.020807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca9</th>\n",
              "      <td>0.138835</td>\n",
              "      <td>0.018906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pca10</th>\n",
              "      <td>0.135592</td>\n",
              "      <td>0.018464</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       설명가능한 분산 비율(고윳값)       기여율\n",
              "pca1           2.361022  0.321512\n",
              "pca2           1.079098  0.146946\n",
              "pca3           0.732532  0.099752\n",
              "pca4           0.399704  0.054430\n",
              "pca5           0.308124  0.041959\n",
              "pca6           0.232358  0.031641\n",
              "pca7           0.169052  0.023021\n",
              "pca8           0.152798  0.020807\n",
              "pca9           0.138835  0.018906\n",
              "pca10          0.135592  0.018464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8FfZ5QJWv-X"
      },
      "source": [
        "### 레이블 기준 설정\n",
        "- 불량품/양품 나누는 기준"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTvypPMtYPSh",
        "outputId": "cf81b1ff-b37b-4dec-d914-8a91ea617c88"
      },
      "source": [
        "# 타겟 데이터\n",
        "df_LRD = fact_data_copy.iloc[:, -4]\n",
        "\n",
        "# 'L.RD' 의 데이터 중 상위 5% 이상이면 불량품, 미만이면 양품으로 결정함\n",
        "#df_LRD = pd.Series(data = np.where(df_LRD.values > df_LRD.quantile(0.95), 1, 0), name='L.RD', index=origin_data.index)\n",
        "\n",
        "# 'L.RD' 의 데이터 중 값이 0.01 이상이면 불량품, 미만이면 양품으로 결정함\n",
        "df_LRD = pd.Series(data = np.where(df_LRD.values >= 0.01, 1, 0), name='L.RD', index=fact_data_copy.index)\n",
        "\n",
        "print(\"레이블 개수\\n\", df_LRD.value_counts())"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "레이블 개수\n",
            " 0    4323\n",
            "1    3822\n",
            "Name: L.RD, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipptn2HZZZke"
      },
      "source": [
        "### 피처 데이터와 레이블 데이터 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sObmbWUqZBSo",
        "outputId": "d2e71023-dcdb-4dc9-e4a6-2dcde7981cc5"
      },
      "source": [
        "# 레이블 없는 데이터에 레이블 시리즈 합치기\n",
        "fact_data_LRD = pd.concat([fact_data, df_LRD], axis=1)\n",
        "print(fact_data_LRD.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8145, 326)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB3TjKRm2aQF"
      },
      "source": [
        "### 훈련/테스트 데이터 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1uKAxsTCWa",
        "outputId": "6a6cc7f7-368f-47b4-c8e0-3ccdb6536301"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 피처/레이블 데이터 나누기\n",
        "X = fact_data_LRD.iloc[:, :-1]\n",
        "y = fact_data_LRD.iloc[:, -1]\n",
        "\n",
        "# 훈련/테스트 데이터 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6108, 325)\n",
            "(2037, 325)\n",
            "(6108,)\n",
            "(2037,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ8BT2QRVHeO"
      },
      "source": [
        "---\n",
        "## 분류 모델 수행\n",
        "- SVM\n",
        "- Emsemble Method\n",
        "    - voting : 여러 알고리즘을 사용하여 비교하고 가장 좋은 모델을 선정\n",
        "        - hard voting(1, 0으로 리턴)\n",
        "        - soft voting(확률로 리턴)\n",
        "    - Bagging : 한 가지 알고리즘을 사용하고 데이터 샘플링을 달리하여 비교\n",
        "    \n",
        "    - Boosting :이전 모델 훈련 결과 나온 가중치를 다음 모델 훈련에 적용\n",
        "    - Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z0egASfnFpv"
      },
      "source": [
        "### Xgboost\n",
        "- 파이썬 외부모듈\n",
        "- 데이터의 구조를 변경해서 사용해야 함\n",
        "- XGB Classifier 이용\n",
        "- 참고 : https://statkclee.github.io/model/model-python-xgboost-hyper.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkUPosyF1HUe"
      },
      "source": [
        "#### XGBClassifier 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_j5hnx71JSX",
        "outputId": "2ce8f403-1936-4b4b-eecd-90b9258dadf5"
      },
      "source": [
        "# XGB 부스트\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_wrapper = XGBClassifier(n_estimators = 400, learning_rate = 0.1, max_depth=7, subsample=0.6)\n",
        "xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='error', eval_set=[(X_test, y_test)], verbose=True)\n",
        "    # early_stopping_rounds : 100번 이상, 400번 이하로 훈련했을 때 모델 성능이 더이상 나아지지 않는 경우 stop\n",
        "    ## 115번 째에서 loss 값이 가장 작았으며, 약 200회 정도만 수행해도 모델 성능이 충분히 개선됨\n",
        "\n",
        "# 분류된 클래스 레이블을 리턴\n",
        "pred = xgb_wrapper.predict(X_test)\n",
        "print(\"######################예측값######################\")\n",
        "print(pred)\n",
        "\n",
        "# 확률 리턴\n",
        "pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
        "print(\"######################예측확률######################\")\n",
        "print(pred_proba)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.310751\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[1]\tvalidation_0-error:0.303878\n",
            "[2]\tvalidation_0-error:0.289151\n",
            "[3]\tvalidation_0-error:0.285714\n",
            "[4]\tvalidation_0-error:0.279332\n",
            "[5]\tvalidation_0-error:0.285714\n",
            "[6]\tvalidation_0-error:0.289151\n",
            "[7]\tvalidation_0-error:0.286696\n",
            "[8]\tvalidation_0-error:0.285714\n",
            "[9]\tvalidation_0-error:0.28326\n",
            "[10]\tvalidation_0-error:0.280805\n",
            "[11]\tvalidation_0-error:0.282278\n",
            "[12]\tvalidation_0-error:0.287187\n",
            "[13]\tvalidation_0-error:0.281787\n",
            "[14]\tvalidation_0-error:0.28326\n",
            "[15]\tvalidation_0-error:0.286205\n",
            "[16]\tvalidation_0-error:0.283751\n",
            "[17]\tvalidation_0-error:0.282278\n",
            "[18]\tvalidation_0-error:0.277369\n",
            "[19]\tvalidation_0-error:0.27786\n",
            "[20]\tvalidation_0-error:0.27786\n",
            "[21]\tvalidation_0-error:0.278841\n",
            "[22]\tvalidation_0-error:0.279823\n",
            "[23]\tvalidation_0-error:0.27786\n",
            "[24]\tvalidation_0-error:0.278351\n",
            "[25]\tvalidation_0-error:0.281787\n",
            "[26]\tvalidation_0-error:0.27786\n",
            "[27]\tvalidation_0-error:0.276387\n",
            "[28]\tvalidation_0-error:0.275896\n",
            "[29]\tvalidation_0-error:0.275405\n",
            "[30]\tvalidation_0-error:0.282769\n",
            "[31]\tvalidation_0-error:0.280805\n",
            "[32]\tvalidation_0-error:0.281787\n",
            "[33]\tvalidation_0-error:0.282769\n",
            "[34]\tvalidation_0-error:0.285223\n",
            "[35]\tvalidation_0-error:0.28866\n",
            "[36]\tvalidation_0-error:0.285223\n",
            "[37]\tvalidation_0-error:0.284732\n",
            "[38]\tvalidation_0-error:0.284732\n",
            "[39]\tvalidation_0-error:0.28326\n",
            "[40]\tvalidation_0-error:0.279823\n",
            "[41]\tvalidation_0-error:0.280805\n",
            "[42]\tvalidation_0-error:0.284732\n",
            "[43]\tvalidation_0-error:0.283751\n",
            "[44]\tvalidation_0-error:0.281296\n",
            "[45]\tvalidation_0-error:0.282769\n",
            "[46]\tvalidation_0-error:0.284242\n",
            "[47]\tvalidation_0-error:0.283751\n",
            "[48]\tvalidation_0-error:0.285714\n",
            "[49]\tvalidation_0-error:0.284732\n",
            "[50]\tvalidation_0-error:0.284242\n",
            "[51]\tvalidation_0-error:0.286696\n",
            "[52]\tvalidation_0-error:0.284242\n",
            "[53]\tvalidation_0-error:0.28326\n",
            "[54]\tvalidation_0-error:0.280314\n",
            "[55]\tvalidation_0-error:0.282769\n",
            "[56]\tvalidation_0-error:0.282769\n",
            "[57]\tvalidation_0-error:0.278351\n",
            "[58]\tvalidation_0-error:0.282278\n",
            "[59]\tvalidation_0-error:0.28326\n",
            "[60]\tvalidation_0-error:0.282278\n",
            "[61]\tvalidation_0-error:0.278841\n",
            "[62]\tvalidation_0-error:0.283751\n",
            "[63]\tvalidation_0-error:0.284732\n",
            "[64]\tvalidation_0-error:0.287678\n",
            "[65]\tvalidation_0-error:0.287187\n",
            "[66]\tvalidation_0-error:0.285223\n",
            "[67]\tvalidation_0-error:0.28326\n",
            "[68]\tvalidation_0-error:0.282278\n",
            "[69]\tvalidation_0-error:0.281296\n",
            "[70]\tvalidation_0-error:0.281296\n",
            "[71]\tvalidation_0-error:0.281787\n",
            "[72]\tvalidation_0-error:0.281787\n",
            "[73]\tvalidation_0-error:0.281296\n",
            "[74]\tvalidation_0-error:0.279823\n",
            "[75]\tvalidation_0-error:0.279823\n",
            "[76]\tvalidation_0-error:0.279823\n",
            "[77]\tvalidation_0-error:0.280805\n",
            "[78]\tvalidation_0-error:0.276878\n",
            "[79]\tvalidation_0-error:0.276878\n",
            "[80]\tvalidation_0-error:0.277369\n",
            "[81]\tvalidation_0-error:0.275405\n",
            "[82]\tvalidation_0-error:0.275896\n",
            "[83]\tvalidation_0-error:0.276387\n",
            "[84]\tvalidation_0-error:0.279332\n",
            "[85]\tvalidation_0-error:0.279823\n",
            "[86]\tvalidation_0-error:0.275896\n",
            "[87]\tvalidation_0-error:0.277369\n",
            "[88]\tvalidation_0-error:0.27786\n",
            "[89]\tvalidation_0-error:0.276387\n",
            "[90]\tvalidation_0-error:0.276387\n",
            "[91]\tvalidation_0-error:0.274914\n",
            "[92]\tvalidation_0-error:0.275405\n",
            "[93]\tvalidation_0-error:0.27246\n",
            "[94]\tvalidation_0-error:0.273441\n",
            "[95]\tvalidation_0-error:0.273932\n",
            "[96]\tvalidation_0-error:0.273441\n",
            "[97]\tvalidation_0-error:0.275405\n",
            "[98]\tvalidation_0-error:0.274423\n",
            "[99]\tvalidation_0-error:0.273441\n",
            "[100]\tvalidation_0-error:0.271969\n",
            "[101]\tvalidation_0-error:0.273441\n",
            "[102]\tvalidation_0-error:0.274423\n",
            "[103]\tvalidation_0-error:0.270987\n",
            "[104]\tvalidation_0-error:0.271478\n",
            "[105]\tvalidation_0-error:0.270987\n",
            "[106]\tvalidation_0-error:0.271969\n",
            "[107]\tvalidation_0-error:0.27295\n",
            "[108]\tvalidation_0-error:0.269514\n",
            "[109]\tvalidation_0-error:0.269514\n",
            "[110]\tvalidation_0-error:0.271478\n",
            "[111]\tvalidation_0-error:0.271969\n",
            "[112]\tvalidation_0-error:0.270005\n",
            "[113]\tvalidation_0-error:0.269514\n",
            "[114]\tvalidation_0-error:0.269023\n",
            "[115]\tvalidation_0-error:0.268532\n",
            "[116]\tvalidation_0-error:0.269023\n",
            "[117]\tvalidation_0-error:0.269023\n",
            "[118]\tvalidation_0-error:0.270005\n",
            "[119]\tvalidation_0-error:0.270005\n",
            "[120]\tvalidation_0-error:0.27295\n",
            "[121]\tvalidation_0-error:0.274423\n",
            "[122]\tvalidation_0-error:0.277369\n",
            "[123]\tvalidation_0-error:0.276387\n",
            "[124]\tvalidation_0-error:0.274423\n",
            "[125]\tvalidation_0-error:0.273441\n",
            "[126]\tvalidation_0-error:0.273441\n",
            "[127]\tvalidation_0-error:0.276878\n",
            "[128]\tvalidation_0-error:0.278351\n",
            "[129]\tvalidation_0-error:0.27786\n",
            "[130]\tvalidation_0-error:0.274914\n",
            "[131]\tvalidation_0-error:0.275896\n",
            "[132]\tvalidation_0-error:0.273441\n",
            "[133]\tvalidation_0-error:0.274423\n",
            "[134]\tvalidation_0-error:0.275405\n",
            "[135]\tvalidation_0-error:0.275405\n",
            "[136]\tvalidation_0-error:0.278351\n",
            "[137]\tvalidation_0-error:0.280805\n",
            "[138]\tvalidation_0-error:0.282278\n",
            "[139]\tvalidation_0-error:0.280314\n",
            "[140]\tvalidation_0-error:0.28326\n",
            "[141]\tvalidation_0-error:0.279332\n",
            "[142]\tvalidation_0-error:0.279332\n",
            "[143]\tvalidation_0-error:0.280314\n",
            "[144]\tvalidation_0-error:0.280805\n",
            "[145]\tvalidation_0-error:0.282278\n",
            "[146]\tvalidation_0-error:0.28326\n",
            "[147]\tvalidation_0-error:0.279823\n",
            "[148]\tvalidation_0-error:0.280314\n",
            "[149]\tvalidation_0-error:0.281787\n",
            "[150]\tvalidation_0-error:0.279332\n",
            "[151]\tvalidation_0-error:0.280314\n",
            "[152]\tvalidation_0-error:0.275405\n",
            "[153]\tvalidation_0-error:0.278841\n",
            "[154]\tvalidation_0-error:0.281787\n",
            "[155]\tvalidation_0-error:0.281296\n",
            "[156]\tvalidation_0-error:0.281296\n",
            "[157]\tvalidation_0-error:0.280805\n",
            "[158]\tvalidation_0-error:0.281296\n",
            "[159]\tvalidation_0-error:0.281787\n",
            "[160]\tvalidation_0-error:0.281296\n",
            "[161]\tvalidation_0-error:0.279823\n",
            "[162]\tvalidation_0-error:0.282769\n",
            "[163]\tvalidation_0-error:0.279823\n",
            "[164]\tvalidation_0-error:0.279823\n",
            "[165]\tvalidation_0-error:0.282769\n",
            "[166]\tvalidation_0-error:0.282278\n",
            "[167]\tvalidation_0-error:0.280805\n",
            "[168]\tvalidation_0-error:0.280805\n",
            "[169]\tvalidation_0-error:0.279823\n",
            "[170]\tvalidation_0-error:0.278351\n",
            "[171]\tvalidation_0-error:0.279823\n",
            "[172]\tvalidation_0-error:0.279332\n",
            "[173]\tvalidation_0-error:0.281296\n",
            "[174]\tvalidation_0-error:0.280314\n",
            "[175]\tvalidation_0-error:0.278841\n",
            "[176]\tvalidation_0-error:0.278841\n",
            "[177]\tvalidation_0-error:0.279332\n",
            "[178]\tvalidation_0-error:0.278841\n",
            "[179]\tvalidation_0-error:0.278841\n",
            "[180]\tvalidation_0-error:0.281296\n",
            "[181]\tvalidation_0-error:0.276387\n",
            "[182]\tvalidation_0-error:0.276878\n",
            "[183]\tvalidation_0-error:0.276878\n",
            "[184]\tvalidation_0-error:0.278351\n",
            "[185]\tvalidation_0-error:0.27786\n",
            "[186]\tvalidation_0-error:0.280314\n",
            "[187]\tvalidation_0-error:0.281787\n",
            "[188]\tvalidation_0-error:0.284242\n",
            "[189]\tvalidation_0-error:0.282278\n",
            "[190]\tvalidation_0-error:0.282769\n",
            "[191]\tvalidation_0-error:0.28326\n",
            "[192]\tvalidation_0-error:0.284732\n",
            "[193]\tvalidation_0-error:0.283751\n",
            "[194]\tvalidation_0-error:0.28326\n",
            "[195]\tvalidation_0-error:0.281296\n",
            "[196]\tvalidation_0-error:0.281787\n",
            "[197]\tvalidation_0-error:0.282769\n",
            "[198]\tvalidation_0-error:0.281296\n",
            "[199]\tvalidation_0-error:0.280805\n",
            "[200]\tvalidation_0-error:0.27786\n",
            "[201]\tvalidation_0-error:0.278351\n",
            "[202]\tvalidation_0-error:0.276878\n",
            "[203]\tvalidation_0-error:0.280314\n",
            "[204]\tvalidation_0-error:0.280314\n",
            "[205]\tvalidation_0-error:0.27786\n",
            "[206]\tvalidation_0-error:0.279332\n",
            "[207]\tvalidation_0-error:0.279332\n",
            "[208]\tvalidation_0-error:0.279332\n",
            "[209]\tvalidation_0-error:0.281296\n",
            "[210]\tvalidation_0-error:0.27786\n",
            "[211]\tvalidation_0-error:0.278841\n",
            "[212]\tvalidation_0-error:0.278351\n",
            "[213]\tvalidation_0-error:0.279823\n",
            "[214]\tvalidation_0-error:0.279332\n",
            "[215]\tvalidation_0-error:0.278841\n",
            "Stopping. Best iteration:\n",
            "[115]\tvalidation_0-error:0.268532\n",
            "\n",
            "######################예측값######################\n",
            "[1 1 1 ... 0 1 0]\n",
            "######################예측확률######################\n",
            "[0.71296555 0.72749233 0.7656854  ... 0.47840577 0.99301744 0.26636747]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzHfHi_pJwqN"
      },
      "source": [
        "### 평가지표\n",
        "- 어떤 평가지표를 사용할지 고민해야 함\n",
        "    - 정확도(accuracy) : TN + TP / 전체\n",
        "    - 정밀도(precision) : TP / (FP + TP)\n",
        "        - Pos로 예측한 것 중 실제 Pos였던 것\n",
        "        - 양성예측도\n",
        "        - Pos 예측 성능을 더 정밀하게 측정하기 위한 평가지표\n",
        "        - FP를 낮추는 데 초점\n",
        "    - 재현율(recall) : TP / (FN + TP)\n",
        "        - 실제 Pos인 것 중 실제 Pos였던 것\n",
        "        - 민감도, TPR(True Positive Rate)\n",
        "        - Pos를 Neg로 판단하면 치명적인 경우 사용\n",
        "        - FN을 낮추는 데 초점\n",
        "    - F1 Score\n",
        "        -  2pr/(p+r)\n",
        "    - ROC 곡선\n",
        "        - 이진분류의 예측 성능 측정에 사용\n",
        "        - FP비율 - TP비율(recall) 곡선\n",
        "- 이 데이터에서는 극소수의 불량품을 판정하지 못하는 것이 치명적임\n",
        "    - 양품은 고객에게 배송되고, 불량품은 재검수 해보는 과정을 생각해보면\n",
        "    - 불량품을 양품으로 판정한 경우, 재검수가 이뤄지지 않고 불량품이 고객에게 배송되면 브랜드 이미지에 타격이 가는 등의 치명적인 문제가 발생함\n",
        "- 따라서 정확도는 적절치 않음. 재현율(recall)이 적절한 지표\n",
        "    - FP가 높고, FN이 낮은지 중점적으로 살펴야 함\n",
        "    - F1 Score가 적절할 것 같음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "5PiFAcNB1JUd",
        "outputId": "ba939339-31f7-42b4-8e33-d5a23d8da0da"
      },
      "source": [
        "# 평가지표출력\n",
        "# 오차행렬 : 정확도, 정밀도, 재현율, f1 스코어, roc_auc_score(곡선면적)\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "print(\"테스트 데이터 수\", y_test.shape)\n",
        "\n",
        "print('오차행렬:\\n', confusion_matrix(y_test, pred))\n",
        "print('정확도:', accuracy_score(y_test, pred).round(3))\n",
        "print('정밀도:', precision_score(y_test, pred).round(3))\n",
        "print('재현율:', recall_score(y_test, pred).round(3))\n",
        "print('f1 스코어:', f1_score(y_test, pred).round(3))\n",
        "\n",
        "# roc_auc_score는 추정확률을 대입해야 함\n",
        "print('roc_auc_score:', roc_auc_score(y_test, pred_proba).round(3))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 수 (2037,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a77b736870f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"테스트 데이터 수\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'오차행렬:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'정확도:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'정밀도:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuCoP5YBbiPH"
      },
      "source": [
        "### 하이퍼 파라미터 조정\n",
        "- GridSearchCV를 이용한 최적의 파라미터 검색\n",
        "- 수행 시간 오래 걸림"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIU8KRbZzyp"
      },
      "source": [
        "# 시간 오래걸려서 자동수행을 방지하기 위해 패키지 주석처리함\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# XGBoost 분류기 생성\n",
        "xgb_clf = xgb.XGBClassifier()\n",
        "\n",
        "# 하이퍼파라미터 격자 생성\n",
        "xgb_param_grid = {'max_depth': [5, 6, 7, 8], \n",
        "                  'subsample': [0.55, 0.6, 0.65]}\n",
        "\n",
        "# GridSearchCV 검증기 생성\n",
        "xgb_grid = GridSearchCV(estimator=xgb_clf,\n",
        "                       param_grid=xgb_param_grid,\n",
        "                       scoring='recall',    # 평가지표 recall 설정 됨!\n",
        "                       n_jobs=-1,\n",
        "                       cv=5,\n",
        "                       refit=True, \n",
        "                       return_train_score=True)\n",
        "\n",
        "# 검증 수행\n",
        "xgb_grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg_Y828U3_wa"
      },
      "source": [
        "# 검증 결과\n",
        "xgb_grid_df = pd.DataFrame(xgb_grid.cv_results_)\n",
        "xgb_grid_df.loc[:, ['mean_test_score', 'params']]\n",
        "\n",
        "\n",
        "## 최고성능\n",
        "best_score = xgb_grid.best_score_\n",
        "# 최고성능을 내는 행을 찾아냄\n",
        "best_row = xgb_grid.best_index_\n",
        "\n",
        "# 최적의 하이퍼 파라미터: max_depth, subsample\n",
        "best_max_depth     = xgb_grid.best_params_[\"max_depth\"]\n",
        "best_max_subsample = xgb_grid.best_params_[\"subsample\"]\n",
        "\n",
        "print('예측모형성능(recall):  \\t', best_score.round(3))\n",
        "print('인덱스:  \\t', best_row)\n",
        "print('max_depth:  \\t', best_max_depth)\n",
        "print('subsample:  \\t', best_max_subsample)\n",
        "# recall : 0.398 , max_depth=7, subsample=0.6 채택!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2OPtQ8RyoAV"
      },
      "source": [
        "### RFE 클래스를 이용한 중요 피처 선정\n",
        "- 참고링크\n",
        "    - https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE\n",
        "    - https://hongl.tistory.com/116\n",
        "- RFE\n",
        "    - recursive feature elimination (재귀적 피처 제거)\n",
        "    - class sklearn.feature_selection.RFE\n",
        "    - RFE(estimator, *, n_features_to_select=None, step=1, verbose=0, importance_getter='auto')\n",
        "        - estimator : 훈련할 모델\n",
        "        - n_features_to_select : 중요 피처 개수 설정(남길 피처 개수). float으로 설정하면 비율\n",
        "        - step : 반복할 때마다 삭제할 피처 개수 설정. float으로 설정하면 비율\n",
        "        - importance_getterstr : 삭제 기준. auto로 두면 회귀에서는 .coef, 분류에서는 feature_importance로 정함\n",
        "\n",
        "- See also\n",
        "    - RFECV\n",
        "        - Recursive feature elimination with built-in cross-validated selection of the best number of features.\n",
        "    - SelectFromModel\n",
        "        - Feature selection based on thresholds of importance weights.\n",
        "    - SequentialFeatureSelector\n",
        "        - Sequential cross-validation based feature selection. Does not rely on importance weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebKiXHMrZ-MO",
        "outputId": "38bcde85-98a8-4591-98d8-7ec42f869853"
      },
      "source": [
        "# RFE 이용하여 중요도 낮은 피처를 제거해가며 훈련해보기\n",
        "# feature_importance_가 낮은 피처를 제거하고 모델 훈련하는 과정을 반복하여 중요한 피처 수를 뽑아냄\n",
        "\n",
        "# XGB 부스트\n",
        "from xgboost import XGBClassifier\n",
        "xgb_wrapper = XGBClassifier(n_estimators = 200, learning_rate = 0.1, max_depth=7, subsample=0.6)\n",
        "\n",
        "# RFE 수행\n",
        "from sklearn.feature_selection import RFE\n",
        "xgb_rfe = RFE(estimator = xgb_wrapper, n_features_to_select = feature_num, verbose=True)    # feature_num : 위에서 pca 분석으로 구함. 전체 데이터의 90%를 설명할 수 있는 n_components 수\n",
        "xgb_rfe.fit(X_train, y_train)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 325 features.\n",
            "Fitting estimator with 324 features.\n",
            "Fitting estimator with 323 features.\n",
            "Fitting estimator with 322 features.\n",
            "Fitting estimator with 321 features.\n",
            "Fitting estimator with 320 features.\n",
            "Fitting estimator with 319 features.\n",
            "Fitting estimator with 318 features.\n",
            "Fitting estimator with 317 features.\n",
            "Fitting estimator with 316 features.\n",
            "Fitting estimator with 315 features.\n",
            "Fitting estimator with 314 features.\n",
            "Fitting estimator with 313 features.\n",
            "Fitting estimator with 312 features.\n",
            "Fitting estimator with 311 features.\n",
            "Fitting estimator with 310 features.\n",
            "Fitting estimator with 309 features.\n",
            "Fitting estimator with 308 features.\n",
            "Fitting estimator with 307 features.\n",
            "Fitting estimator with 306 features.\n",
            "Fitting estimator with 305 features.\n",
            "Fitting estimator with 304 features.\n",
            "Fitting estimator with 303 features.\n",
            "Fitting estimator with 302 features.\n",
            "Fitting estimator with 301 features.\n",
            "Fitting estimator with 300 features.\n",
            "Fitting estimator with 299 features.\n",
            "Fitting estimator with 298 features.\n",
            "Fitting estimator with 297 features.\n",
            "Fitting estimator with 296 features.\n",
            "Fitting estimator with 295 features.\n",
            "Fitting estimator with 294 features.\n",
            "Fitting estimator with 293 features.\n",
            "Fitting estimator with 292 features.\n",
            "Fitting estimator with 291 features.\n",
            "Fitting estimator with 290 features.\n",
            "Fitting estimator with 289 features.\n",
            "Fitting estimator with 288 features.\n",
            "Fitting estimator with 287 features.\n",
            "Fitting estimator with 286 features.\n",
            "Fitting estimator with 285 features.\n",
            "Fitting estimator with 284 features.\n",
            "Fitting estimator with 283 features.\n",
            "Fitting estimator with 282 features.\n",
            "Fitting estimator with 281 features.\n",
            "Fitting estimator with 280 features.\n",
            "Fitting estimator with 279 features.\n",
            "Fitting estimator with 278 features.\n",
            "Fitting estimator with 277 features.\n",
            "Fitting estimator with 276 features.\n",
            "Fitting estimator with 275 features.\n",
            "Fitting estimator with 274 features.\n",
            "Fitting estimator with 273 features.\n",
            "Fitting estimator with 272 features.\n",
            "Fitting estimator with 271 features.\n",
            "Fitting estimator with 270 features.\n",
            "Fitting estimator with 269 features.\n",
            "Fitting estimator with 268 features.\n",
            "Fitting estimator with 267 features.\n",
            "Fitting estimator with 266 features.\n",
            "Fitting estimator with 265 features.\n",
            "Fitting estimator with 264 features.\n",
            "Fitting estimator with 263 features.\n",
            "Fitting estimator with 262 features.\n",
            "Fitting estimator with 261 features.\n",
            "Fitting estimator with 260 features.\n",
            "Fitting estimator with 259 features.\n",
            "Fitting estimator with 258 features.\n",
            "Fitting estimator with 257 features.\n",
            "Fitting estimator with 256 features.\n",
            "Fitting estimator with 255 features.\n",
            "Fitting estimator with 254 features.\n",
            "Fitting estimator with 253 features.\n",
            "Fitting estimator with 252 features.\n",
            "Fitting estimator with 251 features.\n",
            "Fitting estimator with 250 features.\n",
            "Fitting estimator with 249 features.\n",
            "Fitting estimator with 248 features.\n",
            "Fitting estimator with 247 features.\n",
            "Fitting estimator with 246 features.\n",
            "Fitting estimator with 245 features.\n",
            "Fitting estimator with 244 features.\n",
            "Fitting estimator with 243 features.\n",
            "Fitting estimator with 242 features.\n",
            "Fitting estimator with 241 features.\n",
            "Fitting estimator with 240 features.\n",
            "Fitting estimator with 239 features.\n",
            "Fitting estimator with 238 features.\n",
            "Fitting estimator with 237 features.\n",
            "Fitting estimator with 236 features.\n",
            "Fitting estimator with 235 features.\n",
            "Fitting estimator with 234 features.\n",
            "Fitting estimator with 233 features.\n",
            "Fitting estimator with 232 features.\n",
            "Fitting estimator with 231 features.\n",
            "Fitting estimator with 230 features.\n",
            "Fitting estimator with 229 features.\n",
            "Fitting estimator with 228 features.\n",
            "Fitting estimator with 227 features.\n",
            "Fitting estimator with 226 features.\n",
            "Fitting estimator with 225 features.\n",
            "Fitting estimator with 224 features.\n",
            "Fitting estimator with 223 features.\n",
            "Fitting estimator with 222 features.\n",
            "Fitting estimator with 221 features.\n",
            "Fitting estimator with 220 features.\n",
            "Fitting estimator with 219 features.\n",
            "Fitting estimator with 218 features.\n",
            "Fitting estimator with 217 features.\n",
            "Fitting estimator with 216 features.\n",
            "Fitting estimator with 215 features.\n",
            "Fitting estimator with 214 features.\n",
            "Fitting estimator with 213 features.\n",
            "Fitting estimator with 212 features.\n",
            "Fitting estimator with 211 features.\n",
            "Fitting estimator with 210 features.\n",
            "Fitting estimator with 209 features.\n",
            "Fitting estimator with 208 features.\n",
            "Fitting estimator with 207 features.\n",
            "Fitting estimator with 206 features.\n",
            "Fitting estimator with 205 features.\n",
            "Fitting estimator with 204 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFE(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                            colsample_bylevel=1, colsample_bynode=1,\n",
              "                            colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                            max_delta_step=0, max_depth=7, min_child_weight=1,\n",
              "                            missing=None, n_estimators=200, n_jobs=1,\n",
              "                            nthread=None, objective='binary:logistic',\n",
              "                            random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                            scale_pos_weight=1, seed=None, silent=None,\n",
              "                            subsample=0.6, verbosity=1),\n",
              "    n_features_to_select=203, step=1, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlxwk06DLzTN",
        "outputId": "6eec71a3-534f-4a84-9d3a-6471e0e3c67b"
      },
      "source": [
        "# 모델 저장\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/나무플래닛/3. 산출물/xgb_rfe.pickle', 'wb') as f:\n",
        "    pickle.dump(xgb_rfe, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# 저장한 모델 불러오기\n",
        "with open('/content/drive/MyDrive/나무플래닛/3. 산출물/xgb_rfe.pickle', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "model"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFE(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                            colsample_bylevel=1, colsample_bynode=1,\n",
              "                            colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                            max_delta_step=0, max_depth=7, min_child_weight=1,\n",
              "                            missing=nan, n_estimators=200, n_jobs=1,\n",
              "                            nthread=None, objective='binary:logistic',\n",
              "                            random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                            scale_pos_weight=1, seed=None, silent=None,\n",
              "                            subsample=0.6, verbosity=1),\n",
              "    n_features_to_select=203, step=1, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFlilF6o535z",
        "outputId": "42d17ca4-d886-4784-bb3a-9b26d35b2bae"
      },
      "source": [
        "# 선택된(남은) 피처만 필터링\n",
        "# 203개 컬럼에 대한 데이터\n",
        "feature_remain = xgb_rfe.transform(X_train)\n",
        "print(feature_remain.shape)\n",
        "feature_remain"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6108, 203)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.10729677, -0.18069875,  0.0400501 , ..., -1.04879165,\n",
              "        -0.42174732,  1.61      ],\n",
              "       [ 0.01688473, -0.29092286,  0.01000868, ..., -0.78593395,\n",
              "        -0.06966613,  0.        ],\n",
              "       [ 0.02635918,  0.16291014,  0.19282206, ...,  1.14376837,\n",
              "        -0.52975569,  6.98      ],\n",
              "       ...,\n",
              "       [-1.96420869,  0.43064591, -2.59909988, ...,  9.96945313,\n",
              "         5.83043207,  0.59      ],\n",
              "       [-0.53648505, -0.37524549, -0.07684142, ..., -0.22218073,\n",
              "        -0.21495506,  0.65      ],\n",
              "       [-0.83502398, -0.10864962, -0.19841481, ...,  0.80761613,\n",
              "         0.66756352,  2.19      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IJQR_sXBa8r"
      },
      "source": [
        "# 남은 피처 저장\n",
        "np.save('/content/drive/MyDrive/나무플래닛/3. 산출물/rfe_remain_203', feature_remain)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-7gA0DjMz3d"
      },
      "source": [
        "#### 203개로 줄인 피처 꺼내보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P78IeMtyLjL-",
        "outputId": "e2423d2b-0241-43a2-b771-a36b4f0be735"
      },
      "source": [
        "# rfe 객체에서 파라미터 조사\n",
        "\n",
        "# 모델객체\n",
        "print(xgb_rfe.estimator_)\n",
        "\n",
        "# 피처 개수\n",
        "print(xgb_rfe.n_features_)\n",
        "\n",
        "# 피처 중요도 랭킹\n",
        "print('ranking_')\n",
        "print(xgb_rfe.ranking_)\n",
        "print(xgb_rfe.ranking_.shape)\n",
        "\n",
        "# 원래 피처에서 지운 데이터는 False, 남긴 데이터는 True\n",
        "print('support_')\n",
        "print(xgb_rfe.support_)\n",
        "print(xgb_rfe.support_.shape)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
            "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.6, verbosity=1)\n",
            "203\n",
            "ranking_\n",
            "[123  78  93  92  91  90  88  87  86  84  98  80  83  96  99  97  53 111\n",
            " 101  81 104 106 102  65  46   1   1   1   1   1   1   8   1   1   1   1\n",
            "   1   1   1  35  23  20  50   1   1  52  38   1   1   1  55   1   1   1\n",
            "  11   1  21   1  70   1   1   1  59   1   1 110   1  79 113  85  89 121\n",
            " 120   1 114 119 115 109  72 108  57  94 117 116  76 103  62   1  95 100\n",
            "  82  51   1   5   1  64  32  47   1   1  45   1   1   1   1   1   1   1\n",
            "  40   1   1   2   1  16   1   1   1   1   1  43   1   1   1   1   1   1\n",
            "  61   1   1  68   1   1  26   1   1  18  24   1   1  75   1 118  73   1\n",
            "   1   1  10  54  56   1   1   1  71   1   1   1   1  63 122   1   1   1\n",
            "   3   1   1   4   1   1  27   1  28   1   1  33  17   1   1   1   1   1\n",
            "   1   1 105   1 107  66  39  77   1   1   1 112   1   1   1  69   1   9\n",
            "   1   1   1   1   1   1   1   1   1   1  67  48  34  19  25   1   1   1\n",
            "   1   1   1   1   1   1  13   1   1   1   1   1  36   1   1   1   1   1\n",
            "   1   1   1   1   6  37  12  22   1   1   1  30   1   1   1   1   1   1\n",
            "  44   1   1   1   7   1   1   1   1   1   1   1  14   1   1   1  29  41\n",
            "   1   1  49   1   1   1   1   1   1   1   1  74   1   1   1   1  15   1\n",
            "   1   1   1   1   1  60   1   1   1   1   1   1   1   1   1   1   1  58\n",
            "   1   1   1   1   1   1   1   1   1  42   1   1   1  31   1   1   1   1\n",
            "   1]\n",
            "(325,)\n",
            "support_\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True False False False False  True  True False False  True\n",
            "  True  True False  True  True  True False  True False  True False  True\n",
            "  True  True False  True  True False  True False False False False False\n",
            " False  True False False False False False False False False False False\n",
            " False False False  True False False False False  True False  True False\n",
            " False False  True  True False  True  True  True  True  True  True  True\n",
            " False  True  True False  True False  True  True  True  True  True False\n",
            "  True  True  True  True  True  True False  True  True False  True  True\n",
            " False  True  True False False  True  True False  True False False  True\n",
            "  True  True False False False  True  True  True False  True  True  True\n",
            "  True False False  True  True  True False  True  True False  True  True\n",
            " False  True False  True  True False False  True  True  True  True  True\n",
            "  True  True False  True False False False False  True  True  True False\n",
            "  True  True  True False  True False  True  True  True  True  True  True\n",
            "  True  True  True  True False False False False False  True  True  True\n",
            "  True  True  True  True  True  True False  True  True  True  True  True\n",
            " False  True  True  True  True  True  True  True  True  True False False\n",
            " False False  True  True  True False  True  True  True  True  True  True\n",
            " False  True  True  True False  True  True  True  True  True  True  True\n",
            " False  True  True  True False False  True  True False  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True False  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True False  True  True  True False  True  True  True  True\n",
            "  True]\n",
            "(325,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEeeY5YgNoDc",
        "outputId": "55f0c0d2-2f23-4a15-b818-c38f121de4a5"
      },
      "source": [
        "# rfe로 중요한 피처 203개 목록 받기\n",
        "mask = xgb_rfe.support_\n",
        "rfe_col = fact_data.columns[mask].tolist()\n",
        "print(len(rfe_col))\n",
        "\n",
        "# 203개 데이터프레임\n",
        "fact_data_rfe = fact_data[rfe_col]\n",
        "# 저장\n",
        "fact_data_rfe.to_csv('/content/drive/MyDrive/나무플래닛/3. 산출물/fact_data_rfe')\n",
        "fact_data_rfe.info()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "203\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8145 entries, 2016-01-01 07 to 2016-12-31 23\n",
            "Columns: 203 entries, UPPER.AB1.Z1.TMP.1TIC41101.PV to 폐기율...\n",
            "dtypes: float64(203)\n",
            "memory usage: 13.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMaJGtb7TjYw",
        "outputId": "d9448b40-ed08-41e5-9021-57fcbf608a62"
      },
      "source": [
        "# rfe로 추출한 컬럼 203개\n",
        "rfe_col[:]"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['UPPER.AB1.Z1.TMP.1TIC41101.PV',\n",
              " 'UPPER.AB1.Z6.TMP.1TIC41106.PV',\n",
              " 'LOWER.AB1.Z9.TMP.1TIC41152.PV',\n",
              " 'UPPER.AB2.Z20.TMP.1TIC41206.PV',\n",
              " 'LOWER.AB3.Z37.TMP.1TIC41352.PV',\n",
              " 'UPPER.AB5.Z57.TMP.1TIC41501.PV',\n",
              " 'LOWER.AB5.Z69.TMP.1TIC41556.PV',\n",
              " 'UPPER.AB6.Z71.TMP.1TIC41601.PV',\n",
              " 'LOWER.AB6.Z78.TMP.1TIC41651.PV',\n",
              " 'LOWER.AB6.Z83.TMP.1TIC41656.PV',\n",
              " 'LOWER.AB7.Z92.TMP.1TIC41751.PV',\n",
              " 'UPPER.AB8.Z99.TMP.1TIC41801.PV',\n",
              " 'UPPER.AB8.Z101TMP.1TIC41803.PV',\n",
              " 'LOWER.AB10.Z137.TMP.1TIC42054.PV',\n",
              " 'UPPER.AB11.Z142.TMP.1TIC42102.PV',\n",
              " 'UPPER.C1..Z157.TMP.1TIC42203.PV',\n",
              " 'UPPER.C1..Z158.TMP.1TIC42204.PV',\n",
              " 'UPPER.C1..Z159.TMP.1TIC42205.PV',\n",
              " 'LOWER.C1..Z168.TMP.1TIC42257.PV',\n",
              " 'UPPER.C2..Z169.TMP.1TIC42301.PV',\n",
              " 'UPPER.C2..Z170.TMP.1TIC42302.PV',\n",
              " 'UPPER.C2..Z173.TMP.1TIC42305.PV',\n",
              " 'LOWER.C2..Z176.TMP.1TIC42351.PV',\n",
              " 'UPPER.C3..Z183.TMP.1TIC42401.PV',\n",
              " 'LOWER.C3..Z193TMP.1TIC42454.PV',\n",
              " 'LOWER.C3..Z196.TMP.1TIC42457.PV',\n",
              " 'UPPER.C4..Z201.TMP.1TIC42505.PV',\n",
              " 'LOWER.C4..Z204.TMP.1TIC42551.PV',\n",
              " 'LIFT.OUT.ROL.MTR.M1.CUR.1WII40101.PV',\n",
              " 'LEHR.DRV.MTR..M8.1.CUR.1WII40112.PV',\n",
              " 'X1WOS45102_PV.1',\n",
              " 'TMP.GLASS..BAY.2.1TI30102.PV',\n",
              " 'TMP.GLASS..BAY.5.1TI30105.PV',\n",
              " 'TMP.TIN..BAY.5.LEFT.1TI30205.PV',\n",
              " 'TMP.TIN..BAY.10.LEFT.1TI30209.PV',\n",
              " 'TMP.GLASS..ZONE.AB1.E1.1TI40201.PV',\n",
              " 'TMP.GLASS..ZONE.AB1.E3.1TI40203.PV',\n",
              " 'TMP.GLASS..ZONE.AB11.L5.1TI40225.PV',\n",
              " 'TMP.GLASS..Z_RET.E1.1TI40241.PV',\n",
              " 'TMP.GLASS..ZONE.F.E1.1TI40251.PV',\n",
              " 'X.10.BAY.LEFT.PRESSURE.1CLBAY10LEFT_CPV',\n",
              " 'X.1.BAY.LEFT.PRESSURE.1CLBAY1LEFT_CPV',\n",
              " 'X.1.LEHR.SO2.ANALYZER.1AI44110.PV',\n",
              " 'X.1.LEHR.O2.ANALYZER.1AI44111.PV',\n",
              " 'X.2.LEHR.O2.ANALYZER.1AI44113.PV',\n",
              " 'BATH.AMBIENT.3.BAY.LEFT.1TI31003_PV',\n",
              " 'N2.TO.EA1313B.1FI33527A_PV',\n",
              " 'N2.TO.EA1315B.1FI33528A_PV',\n",
              " 'EXIT.LIP.PLATE.LEFT.1TI30604.PV',\n",
              " 'E.L.DB.LEFT..N2.FLOW.1FI33501.PV',\n",
              " 'N2.TO.HOOD.DOWN.STREAM.1FI33505A_PV',\n",
              " 'N2.TO.HOOD.UP.STREAM.1FI33506A_PV',\n",
              " 'TMP.GLASS..LEFT.EXIT.1TIC30109.PV',\n",
              " 'DROSS.BOX.PRESS.1PI40301.PV',\n",
              " 'LEHR.AB1.PRESS.1PI40302.PV',\n",
              " 'DB.HEAT.TOP.7.1.TMP.1TI40307.PV',\n",
              " 'DB.HEAT.BTM.LEFT.1.TMP.1TI40315.PV',\n",
              " 'DB.HEAT.BTM.LEFT.2.TMP.1TI40316.PV',\n",
              " 'DB.BTM.UP.STM.TC.RE.1TI40403_PV',\n",
              " 'DB.BTM.DN.STM.TC.LE.1TI40404_PV',\n",
              " 'DB.BTM.DN.STM.TC.RC.1TI40407_PV',\n",
              " 'DB.BTM.DN.STM.TC.RE.1TI40408_PV',\n",
              " 'DB.HEAT.TOP.7.1.2.TMP.CT.1JI40307.PV',\n",
              " 'DB.HEAT.BOTTOM.1.1JIC40308.PV',\n",
              " 'DB.HEAT.BOTTOM.3.1JIC40310.PV',\n",
              " 'DB.HEAT.BOTTOM.7.1JIC40314.PV',\n",
              " 'ROOF.HT.BAY.10.TOTAL.PWR.1CLBAY10_CPV',\n",
              " 'ROOF.HT.BAY.11.TOTAL.PWR.1CLBAY11_CPV',\n",
              " 'ROOF.HT.BAY.5.TOTAL.PWR.1CLBAY5_CPV',\n",
              " 'ROOF.HT.BAY.6.TOTAL.PWR.1CLBAY6_CPV',\n",
              " 'ROOF.HT.BAY.7.TOTAL.PWR.1CLBAY7_CPV',\n",
              " 'ROOF.HT.BAY.9.TOTAL.PWR.1CLBAY9_CPV',\n",
              " 'ROOF.HT.BAY.TOTAL.PWR.1CLBAYTOT_CPV',\n",
              " 'ROOF.HEATING.Zone.3.1JIC31103.PV.1',\n",
              " 'ROOF.HEATING.Zone.4.1JIC31104.PV.1',\n",
              " 'ROOF.HEATING.Zone10.1JIC31110.PV',\n",
              " 'ROOF.HEATING.Zone11.1JIC31111.PV',\n",
              " 'ROOF.HEATING.Zone12.1JIC31112.PV',\n",
              " 'ROOF.HEATING.Zone21.1JIC31121.PV',\n",
              " 'ROOF.HEATING.Zone22.1JIC31122.PV',\n",
              " 'ROOF.HEATING.Zone25.1JIC31125.PV',\n",
              " 'ROOF.HEATING.Zone27.1JIC31127.PV',\n",
              " 'ROOF.HEATING.Zone30.1JIC31130.PV',\n",
              " 'ROOF.HEATING.Zone32.1JIC31132.PV',\n",
              " 'ROOF.HEATING.Zone36.1JIC31136.PV',\n",
              " 'ROOF.HEATING.Zone40.1JIC31140.PV',\n",
              " 'ROOF.HEATING.Zone41.1JIC31141.PV',\n",
              " 'ROOF.HEATING.Zone42.1JIC31142.PV',\n",
              " 'ROOF.HEATING.Zone43.1JIC31143.PV',\n",
              " 'ROOF.HEATING.Zone44.1JIC31144.PV',\n",
              " 'ROOF.HEATING.Zone45.1JIC31145.PV',\n",
              " 'ROOF.HEATING.Zone49.1JIC31149.PV',\n",
              " 'ROOF.HEATING.Zone53.1JIC31153.PV',\n",
              " 'ROOF.HEATING.Zone63.1JIC31163.PV',\n",
              " 'ROOF.HEATING.Zone64.1JIC31164.PV',\n",
              " 'ROOF.HEATING.Zone73.1JIC31173.PV',\n",
              " 'ROOF.HEATING.Zone80.1JIC31180.PV',\n",
              " 'ROOF.HEATING.Zone81.1JIC31181.PV',\n",
              " 'ROOF.HEATING.Zone86.1JIC31186.PV',\n",
              " 'ATM.FLOW.SECT.2.N2.1FI33401.PV',\n",
              " 'ATM.FLOW.SECT.3.N2.1FI33403.PV',\n",
              " 'ATM.FLOW.SECT.3.N2.H2.1FI33404.PV',\n",
              " 'ATM.FLOW.SECT.4.N2.1FI33405.PV',\n",
              " 'ATM.FLOW.SECT.5.N2.1FI33407.PV',\n",
              " 'ATM.FLOW.SECT.6.N2.1FI33409.PV',\n",
              " 'ATM.FLOW.SECT.7.N2.1FI33411.PV',\n",
              " 'ATM.FLOW.SECT.8.N2.1FI33413.PV',\n",
              " 'ATM.FLOW.SECT.1.N2.H2.1FI33424.PV',\n",
              " 'ATM.FLOW.SECT.9.N2.H2.1FIC33416.PV.1',\n",
              " 'ATM.FLOW.SECT.10.N2.1FIC33417.PV',\n",
              " 'ATM.N2.H2.5..함유율.1CLFI33402_CPV',\n",
              " 'ATM.N2.H2.9..함유율.1CLFI33406_CPV',\n",
              " 'ATM.N2.H2.9..함유율.1CLFI33416_CPV',\n",
              " 'LOR.1.L.Axis',\n",
              " 'LOR.1.L.Hori',\n",
              " 'LOR.2.L.Axis',\n",
              " 'LOR.2.L.Hori',\n",
              " 'LOR.3.L.Axis',\n",
              " 'LOR.3.L.Hori',\n",
              " 'bay2_4',\n",
              " 'bay4_5',\n",
              " 'bay5_6',\n",
              " 'bay6_7',\n",
              " 'bay7_8',\n",
              " 'l_r_tin_bay5',\n",
              " 'l_r_tin_bay7',\n",
              " 'l_tin_bay_5_7',\n",
              " 'l_tin_bay_7_10',\n",
              " 'lc_rc_btm_dn',\n",
              " 'le_re_btm_dn',\n",
              " 'c_btm_up_dn',\n",
              " 'rc_btm_up_dn',\n",
              " 're_btm_up_dn',\n",
              " 'top_5',\n",
              " 'top_7',\n",
              " 'D_AB1_U_LR',\n",
              " 'D_AB2_U_LR',\n",
              " 'D_AB2_L_LR',\n",
              " 'D_AB3_U_LR',\n",
              " 'D_AB3_L_LR',\n",
              " 'D_AB4_U_LR',\n",
              " 'D_AB4_L_LR',\n",
              " 'D_AB5_L_LR',\n",
              " 'D_AB6_U_LR',\n",
              " 'D_AB6_L_LR',\n",
              " 'D_AB7_L_LR',\n",
              " 'D_AB8_U_LR',\n",
              " 'D_AB8_L_LR',\n",
              " 'D_AB9_U_LR',\n",
              " 'D_AB9_L_LR',\n",
              " 'D_AB10_U_LR',\n",
              " 'D_AB10_L_LR',\n",
              " 'D_AB11_L_LR',\n",
              " 'D_AB1_L_UL',\n",
              " 'D_AB2_L_UL',\n",
              " 'D_AB5_L_UL',\n",
              " 'D_AB7_L_UL',\n",
              " 'D_AB9_L_UL',\n",
              " 'D_AB10_L_UL',\n",
              " 'D_AB11_L_UL',\n",
              " 'D_C1_U_LR',\n",
              " 'D_C1_L_LR',\n",
              " 'D_C2_U_LR',\n",
              " 'D_C2_L_LR',\n",
              " 'D_C3_U_LR',\n",
              " 'D_C4_U_LR',\n",
              " 'D_C4_L_LR',\n",
              " 'D_C1_L_UL',\n",
              " 'D_C2_L_UL',\n",
              " 'D_GLS_AB1_LR',\n",
              " 'D_GLS_AB11_LR',\n",
              " 'D_GLS_AB7_LR',\n",
              " 'D_GLS_C4_LR',\n",
              " 'D_GLS_F_LR',\n",
              " 'D_GLS_RET_LR',\n",
              " 'S_AB1_AB2_L_L',\n",
              " 'S_AB2_AB3_U_L',\n",
              " 'S_AB2_AB3_L_L',\n",
              " 'S_AB3_AB4_U_L',\n",
              " 'S_AB4_AB5_U_L',\n",
              " 'S_AB5_AB6_U_L',\n",
              " 'S_AB6_AB7_U_L',\n",
              " 'S_AB6_AB7_L_L',\n",
              " 'S_AB7_AB8_U_L',\n",
              " 'S_AB7_AB8_L_L',\n",
              " 'S_AB8_AB9_U_L',\n",
              " 'S_AB9_AB10_U_L',\n",
              " 'S_AB9_AB10_L_L',\n",
              " 'S_AB10_AB11_U_L',\n",
              " 'S_AB10_AB11_L_L',\n",
              " 'S_AB11_C1_U_L',\n",
              " 'S_AB11_C1_L_L',\n",
              " 'S_C1_C2_U_L',\n",
              " 'S_C1_C2_L_L',\n",
              " 'S_C2_C3_U_L',\n",
              " 'S_C3_C4_U_L',\n",
              " 'S_AB1_AB11_L',\n",
              " 'S_AB11_AB7_L',\n",
              " 'S_C4_RET_L',\n",
              " 'S_RET_F_L',\n",
              " 'STD_U_L',\n",
              " 'STD_GLS_L',\n",
              " '폐기율...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    }
  ]
}